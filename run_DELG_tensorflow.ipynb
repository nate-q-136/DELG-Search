{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5J0-KQAJaONY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install DELF"
      ],
      "metadata": {
        "id": "Fd6aZmHVsv8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "os.chdir('/content/drive/MyDrive/5_NCKH')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FDGpWLdGL7nY",
        "outputId": "08b7f2fb-c37e-4960-f253-dccb0e85d930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/5_NCKH'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/tensorflow/models.git"
      ],
      "metadata": {
        "id": "KHa1fgqUs1VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('./models/research/delf/delf/python/training')"
      ],
      "metadata": {
        "id": "YE0rwda3uxDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MqAvDIFvJZ_",
        "outputId": "55b5070a-02b0-4cdb-d144-8e7110549990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build_image_dataset.py\tglobal_features_utils.py  matched_images_demo.png  tensorboard_utils.py\n",
            "delg\t\t\t__init__.py\t\t  model\t\t\t   train.py\n",
            "download_dataset.sh\tinstall_delf.sh\t\t  __pycache__\n",
            "global_features\t\tlosses\t\t\t  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash install_delf.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ4qRO8ju5gJ",
        "outputId": "e6392d8d-bc20-4f41-e9f2-7ccb0f97b921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing TensorFlow\n",
            "Requirement already satisfied: Tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->Tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->Tensorflow) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->Tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->Tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->Tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->Tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->Tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->Tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->Tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->Tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->Tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->Tensorflow) (3.0.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->Tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->Tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->Tensorflow) (0.1.2)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.3.0\n",
            "    Uninstalling typeguard-4.3.0:\n",
            "      Successfully uninstalled typeguard-4.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n",
            "Installing TensorFlow for GPU\n",
            "Installing TF-Slim from source: \n",
            "Cloning into 'tf-slim'...\n",
            "remote: Enumerating objects: 834, done.\u001b[K\n",
            "remote: Counting objects: 100% (207/207), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 834 (delta 138), reused 178 (delta 129), pack-reused 627 (from 1)\u001b[K\n",
            "Receiving objects: 100% (834/834), 799.35 KiB | 4.23 MiB/s, done.\n",
            "Resolving deltas: 100% (578/578), done.\n",
            "Note: switching to 'a143c8241b12e00a441678f9d527c6a488166863'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "Processing /content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/training/tf-slim\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf_slim==1.1.0) (1.4.0)\n",
            "Building wheels for collected packages: tf_slim\n",
            "  Building wheel for tf_slim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tf_slim: filename=tf_slim-1.1.0-py3-none-any.whl size=355172 sha256=f76b66a93de0274e5dc49f97df541dc3e266150da2c92c5310be1217e826428e\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/85/6f/140c4c2aa75dfc237f79b7fd889687b5230a255603ef8798bb\n",
            "Successfully built tf_slim\n",
            "Installing collected packages: tf_slim\n",
            "  Attempting uninstall: tf_slim\n",
            "    Found existing installation: tf-slim 1.1.0\n",
            "    Uninstalling tf-slim-1.1.0:\n",
            "      Successfully uninstalled tf-slim-1.1.0\n",
            "Successfully installed tf_slim-1.1.0\n",
            "Downloading Protobuf compiler from https://github.com/google/protobuf/releases/download/v3.3.0/protoc-3.3.0-linux-x86_64.zip\n",
            "Archive:  protoc-3.3.0-linux-x86_64.zip\n",
            "   creating: protoc/include/\n",
            "   creating: protoc/include/google/\n",
            "   creating: protoc/include/google/protobuf/\n",
            "  inflating: protoc/include/google/protobuf/any.proto  \n",
            "  inflating: protoc/include/google/protobuf/api.proto  \n",
            "   creating: protoc/include/google/protobuf/compiler/\n",
            "  inflating: protoc/include/google/protobuf/compiler/plugin.proto  \n",
            "  inflating: protoc/include/google/protobuf/descriptor.proto  \n",
            "  inflating: protoc/include/google/protobuf/duration.proto  \n",
            "  inflating: protoc/include/google/protobuf/empty.proto  \n",
            "  inflating: protoc/include/google/protobuf/field_mask.proto  \n",
            "  inflating: protoc/include/google/protobuf/source_context.proto  \n",
            "  inflating: protoc/include/google/protobuf/struct.proto  \n",
            "  inflating: protoc/include/google/protobuf/timestamp.proto  \n",
            "  inflating: protoc/include/google/protobuf/type.proto  \n",
            "  inflating: protoc/include/google/protobuf/wrappers.proto  \n",
            "   creating: protoc/bin/\n",
            "  inflating: protoc/bin/protoc       \n",
            "  inflating: protoc/readme.txt       \n",
            "Compiling DELF Protobufs\n",
            "Cleaning up Protobuf compiler download\n",
            "Installing matplotlib, numpy, scikit-image, scipy and python3-tk\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.24.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.4.1)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-tk is already the newest version (3.10.8-1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Installing object detection\n",
            "\u001b[31mERROR: Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0mUnable to install the object_detection package. Exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf==3.20.3\n",
        "!pip install pandas\n",
        "!pip install tensorflow-object-detection-api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3kZgtnzzisy",
        "outputId": "d5f1fa46-701d-476b-c6a1-d204d4573033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Collecting tensorflow-object-detection-api\n",
            "  Downloading tensorflow_object_detection_api-0.1.1.tar.gz (577 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.4/577.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-object-detection-api) (10.4.0)\n",
            "Requirement already satisfied: Matplotlib>=2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-object-detection-api) (3.7.1)\n",
            "Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-object-detection-api) (3.0.11)\n",
            "Requirement already satisfied: Protobuf in /usr/local/lib/python3.10/dist-packages (from tensorflow-object-detection-api) (3.20.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from tensorflow-object-detection-api) (4.9.4)\n",
            "Collecting jupyter (from tensorflow-object-detection-api)\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from tensorflow-object-detection-api) (2.17.0)\n",
            "Collecting contextlib2 (from tensorflow-object-detection-api)\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow-object-detection-api) (0.44.0)\n",
            "Collecting twine (from tensorflow-object-detection-api)\n",
            "  Downloading twine-5.1.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (2.8.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter->tensorflow-object-detection-api) (6.5.5)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter->tensorflow-object-detection-api) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter->tensorflow-object-detection-api) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter->tensorflow-object-detection-api) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter->tensorflow-object-detection-api) (7.7.1)\n",
            "Collecting jupyterlab (from jupyter->tensorflow-object-detection-api)\n",
            "  Downloading jupyterlab-4.2.5-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (3.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.37.1)\n",
            "Collecting pkginfo>=1.8.1 (from twine->tensorflow-object-detection-api)\n",
            "  Downloading pkginfo-1.11.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting readme-renderer>=35.0 (from twine->tensorflow-object-detection-api)\n",
            "  Downloading readme_renderer-44.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting requests-toolbelt!=0.9.0,>=0.8.0 (from twine->tensorflow-object-detection-api)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from twine->tensorflow-object-detection-api) (2.2.3)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.10/dist-packages (from twine->tensorflow-object-detection-api) (8.5.0)\n",
            "Requirement already satisfied: keyring>=15.1 in /usr/lib/python3/dist-packages (from twine->tensorflow-object-detection-api) (23.5.0)\n",
            "Collecting rfc3986>=1.4.0 (from twine->tensorflow-object-detection-api)\n",
            "  Downloading rfc3986-2.0.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from twine->tensorflow-object-detection-api) (13.9.2)\n",
            "Collecting pkginfo>=1.8.1 (from twine->tensorflow-object-detection-api)\n",
            "  Downloading pkginfo-1.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=3.6->twine->tensorflow-object-detection-api) (3.20.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow->tensorflow-object-detection-api) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow->tensorflow-object-detection-api) (0.13.0)\n",
            "Collecting nh3>=0.2.14 (from readme-renderer>=35.0->twine->tensorflow-object-detection-api)\n",
            "  Downloading nh3-0.2.18-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting docutils>=0.21.2 (from readme-renderer>=35.0->twine->tensorflow-object-detection-api)\n",
            "  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: Pygments>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from readme-renderer>=35.0->twine->tensorflow-object-detection-api) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->tensorflow-object-detection-api) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->tensorflow-object-detection-api) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->tensorflow-object-detection-api) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->twine->tensorflow-object-detection-api) (3.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow->tensorflow-object-detection-api) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow->tensorflow-object-detection-api) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow->tensorflow-object-detection-api) (3.0.4)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (6.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (3.6.9)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (3.0.13)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter->tensorflow-object-detection-api) (3.0.48)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting httpx>=0.25.0 (from jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting ipykernel (from jupyter->tensorflow-object-detection-api)\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter->tensorflow-object-detection-api) (3.1.4)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter->tensorflow-object-detection-api) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading jupyter_server-2.14.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter->tensorflow-object-detection-api) (0.2.4)\n",
            "Requirement already satisfied: tomli>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter->tensorflow-object-detection-api) (2.0.2)\n",
            "Collecting comm>=0.1.1 (from ipykernel->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (1.6.6)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (24.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (3.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.10.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (1.3.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (23.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (1.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->tensorflow-object-detection-api) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx>=0.25.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->tensorflow-object-detection-api) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->jupyterlab->jupyter->tensorflow-object-detection-api) (4.3.6)\n",
            "Collecting jupyter-client (from jupyter-console->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter-events>=0.9.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading jupyter_events-0.10.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter->tensorflow-object-detection-api) (21.2.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->tensorflow-object-detection-api) (2.16.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading json5-0.9.25-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->tensorflow-object-detection-api) (4.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->twine->tensorflow-object-detection-api) (0.1.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter->tensorflow-object-detection-api) (2.20.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->tensorflow-object-detection-api) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter->tensorflow-object-detection-api) (0.7.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter->tensorflow-object-detection-api) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter->tensorflow-object-detection-api) (0.5.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter->tensorflow-object-detection-api) (1.2.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->tensorflow-object-detection-api) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->tensorflow-object-detection-api) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->tensorflow-object-detection-api) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->tensorflow-object-detection-api) (0.20.0)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->tensorflow-object-detection-api) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->tensorflow-object-detection-api) (2.22)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api) (24.8.0)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->tensorflow-object-detection-api)\n",
            "  Downloading types_python_dateutil-2.9.0.20241003-py3-none-any.whl.metadata (1.9 kB)\n",
            "Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading twine-5.1.1-py3-none-any.whl (38 kB)\n",
            "Downloading pkginfo-1.10.0-py3-none-any.whl (30 kB)\n",
            "Downloading readme_renderer-44.0-py3-none-any.whl (13 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rfc3986-2.0.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading jupyterlab-4.2.5-py3-none-any.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading docutils-0.21.2-py3-none-any.whl (587 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.4/587.4 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.14.2-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nh3-0.2.18-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.2/769.2 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.9.25-py3-none-any.whl (30 kB)\n",
            "Downloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241003-py3-none-any.whl (9.7 kB)\n",
            "Building wheels for collected packages: tensorflow-object-detection-api\n",
            "  Building wheel for tensorflow-object-detection-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-object-detection-api: filename=tensorflow_object_detection_api-0.1.1-py3-none-any.whl size=844489 sha256=b24554b99436b9e738f9451c8435dfa85e3de61c9995741a61272bc7dcdbf36f\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/55/68/c084bc2cd93c41fd8f7e2ef9e6bbcb2c35a3e4b49e42044d02\n",
            "Successfully built tensorflow-object-detection-api\n",
            "Installing collected packages: nh3, uri-template, types-python-dateutil, rfc3986-validator, rfc3986, rfc3339-validator, python-json-logger, pkginfo, overrides, jsonpointer, json5, jedi, h11, fqdn, docutils, contextlib2, comm, async-lru, requests-toolbelt, readme-renderer, jupyter-server-terminals, jupyter-client, httpcore, arrow, twine, isoduration, ipykernel, httpx, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter, tensorflow-object-detection-api\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.18.1\n",
            "    Uninstalling docutils-0.18.1:\n",
            "      Successfully uninstalled docutils-0.18.1\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.5.6\n",
            "    Uninstalling ipykernel-5.5.6:\n",
            "      Successfully uninstalled ipykernel-5.5.6\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.24.0\n",
            "    Uninstalling jupyter-server-1.24.0:\n",
            "      Successfully uninstalled jupyter-server-1.24.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sphinx 5.0.2 requires docutils<0.19,>=0.14, but you have docutils 0.21.2 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.29.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arrow-1.3.0 async-lru-2.0.4 comm-0.2.2 contextlib2-21.6.0 docutils-0.21.2 fqdn-1.5.1 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 ipykernel-6.29.5 isoduration-20.11.0 jedi-0.19.1 json5-0.9.25 jsonpointer-3.0.0 jupyter-1.1.1 jupyter-client-7.4.9 jupyter-events-0.10.0 jupyter-lsp-2.2.5 jupyter-server-2.14.2 jupyter-server-terminals-0.5.3 jupyterlab-4.2.5 jupyterlab-server-2.27.3 nh3-0.2.18 overrides-7.7.0 pkginfo-1.10.0 python-json-logger-2.0.7 readme-renderer-44.0 requests-toolbelt-1.0.0 rfc3339-validator-0.1.4 rfc3986-2.0.0 rfc3986-validator-0.1.1 tensorflow-object-detection-api-0.1.1 twine-5.1.1 types-python-dateutil-2.9.0.20241003 uri-template-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/5_NCKH/models/research/delf/')"
      ],
      "metadata": {
        "id": "ZIgvGAhx083L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTPMy5TG5RyO",
        "outputId": "c2b83dfe-30d9-4837-bc5c-b573e271a8f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/drive/MyDrive/5_NCKH/models/research/delf\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from delf==2.0) (1.4.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from delf==2.0) (3.20.3)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from delf==2.0) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.1 in /usr/local/lib/python3.10/dist-packages (from delf==2.0) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from delf==2.0) (1.13.1)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from delf==2.0) (2.17.0)\n",
            "Requirement already satisfied: tf_slim>=1.1 in /usr/local/lib/python3.10/dist-packages (from delf==2.0) (1.1.0)\n",
            "Requirement already satisfied: tensorflow_probability>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from delf==2.0) (0.24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->delf==2.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->delf==2.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->delf==2.0) (2024.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (24.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->delf==2.0) (0.37.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability>=0.9.0->delf==2.0) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability>=0.9.0->delf==2.0) (3.1.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability>=0.9.0->delf==2.0) (0.1.8)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2.0->delf==2.0) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.2.0->delf==2.0) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.2.0->delf==2.0) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.2.0->delf==2.0) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.2.0->delf==2.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.2.0->delf==2.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.2.0->delf==2.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.2.0->delf==2.0) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=2.2.0->delf==2.0) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=2.2.0->delf==2.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=2.2.0->delf==2.0) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow>=2.2.0->delf==2.0) (3.0.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=2.2.0->delf==2.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=2.2.0->delf==2.0) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow>=2.2.0->delf==2.0) (0.1.2)\n",
            "Building wheels for collected packages: delf\n",
            "  Building wheel for delf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for delf: filename=delf-2.0-py3-none-any.whl size=182013 sha256=7a6dfc85b0ed5f66dc6f2563518eb0ad73a8f5084a374f89a71c50f4d246b064\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9engz9td/wheels/ee/bd/63/5574657758242e747d54fd6164a13169269d259f483960d0c3\n",
            "Successfully built delf\n",
            "Installing collected packages: delf\n",
            "Successfully installed delf-2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PYTHONPATH=$PYTHONPATH:`pwd`"
      ],
      "metadata": {
        "id": "PXONfbue1Fv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import delf    # no errorr"
      ],
      "metadata": {
        "id": "vHM0b8rJ1OFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quickstart DELG"
      ],
      "metadata": {
        "id": "XtilcYGXG1bW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset"
      ],
      "metadata": {
        "id": "1em7Boe01du_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/training')"
      ],
      "metadata": {
        "id": "IdZOshu-15My"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jPn0x3f-1jbG",
        "outputId": "7d25722a-69da-4126-9c6c-23d41f2a6dfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/training'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ./delg/data"
      ],
      "metadata": {
        "id": "3d5Ka3WQ1ge6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/training/delg/data')"
      ],
      "metadata": {
        "id": "85tLjCpA2Q_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7JZTVlK72NyP",
        "outputId": "26ca0c99-108c-4b28-f51e-9d23db5bea6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/training/delg/data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Oxford dataset.\n",
        "!wget http://www.robots.ox.ac.uk/~vgg/data/oxbuildings/oxbuild_images.tgz\n",
        "!mkdir oxford5k_images\n",
        "!tar -xvzf oxbuild_images.tgz -C oxford5k_images/"
      ],
      "metadata": {
        "id": "668bspBO2KTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://cmp.felk.cvut.cz/revisitop/data/datasets/roxford5k/gnd_roxford5k.mat\n",
        "!wget http://cmp.felk.cvut.cz/cnnimageretrieval/data/test/roxford5k/gnd_roxford5k.pkl"
      ],
      "metadata": {
        "id": "thIchI_83Z2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Model pretrain"
      ],
      "metadata": {
        "id": "lpxLq4ni3w0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yLcKfAVw34bq",
        "outputId": "3d3cbde6-12e2-4968-b7ae-6da3286fb029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/delg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/delg')"
      ],
      "metadata": {
        "id": "3SAbb4ZF36Y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From models/research/delf/delf/python/delg\n",
        "!mkdir parameters"
      ],
      "metadata": {
        "id": "jIxAXg1J3z0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/delg/parameters')"
      ],
      "metadata": {
        "id": "5ZMyNJuu4Hv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# R50-DELG-GLD model.\n",
        "!wget http://storage.googleapis.com/delf/r50delg_gld_20200814.tar.gz\n",
        "!tar -xvzf r50delg_gld_20200814.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owx9MYQm4POi",
        "outputId": "de9fd8e9-c8e1-4194-aca8-13a29a2cc912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-18 18:25:58--  http://storage.googleapis.com/delf/r50delg_gld_20200814.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.210.207, 173.194.212.207, 173.194.215.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.210.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 106082379 (101M) [application/x-gzip]\n",
            "Saving to: ‘r50delg_gld_20200814.tar.gz’\n",
            "\n",
            "r50delg_gld_2020081 100%[===================>] 101.17M  68.0MB/s    in 1.5s    \n",
            "\n",
            "2024-10-18 18:25:59 (68.0 MB/s) - ‘r50delg_gld_20200814.tar.gz’ saved [106082379/106082379]\n",
            "\n",
            "r50delg_gld_20200814/\n",
            "r50delg_gld_20200814/saved_model.pb\n",
            "r50delg_gld_20200814/variables/\n",
            "r50delg_gld_20200814/variables/variables.data-00000-of-00001\n",
            "r50delg_gld_20200814/variables/variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature extraction"
      ],
      "metadata": {
        "id": "kbfjhfqa4lqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Query feature extraction"
      ],
      "metadata": {
        "id": "0-Adr0B_4otZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0S7vpV7y4vzJ",
        "outputId": "1a5be309-8670-4f0d-9e6e-fd2620140674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/5_NCKH/models/research/delf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/delg\")"
      ],
      "metadata": {
        "id": "vUaXQSqX40pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From models/research/delf/delf/python/delg\n",
        "!export PYTHONPATH=$PYTHONPATH:/content/drive/MyDrive/5_NCKH/models/research/delf && \\\n",
        "python3 extract_features.py \\\n",
        "  --delf_config_path r50delg_gld_config.pbtxt \\\n",
        "  --dataset_file_path ./../training/delg/data/gnd_roxford5k.mat \\\n",
        "  --images_dir ./../training/delg/data/oxford5k_images \\\n",
        "  --image_set query \\\n",
        "  --output_features_dir ./../training/delg/data/oxford5k_features/query\n",
        "\n",
        "# !python3 extract_features.py \\\n",
        "#   --delf_config_path r50delg_gld_config.pbtxt \\\n",
        "#   --dataset_file_path ~/delg/data/gnd_roxford5k.mat \\\n",
        "#   --images_dir ~/delg/data/oxford5k_images \\\n",
        "#   --image_set query \\\n",
        "#   --output_features_dir ~/delg/data/oxford5k_features/query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hThBkktT4lSZ",
        "outputId": "f844839b-eb4a-4889-ae4d-877bb94b881c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing image 50 out of 70, last 50 images took 338.588483 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Index feature extraction"
      ],
      "metadata": {
        "id": "_JeaRPI5CzRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From models/research/delf/delf/python/delg\n",
        "!export PYTHONPATH=$PYTHONPATH:/content/drive/MyDrive/5_NCKH/models/research/delf && \\\n",
        "python3 extract_features.py \\\n",
        "  --delf_config_path r50delg_gld_config.pbtxt \\\n",
        "  --dataset_file_path ./../training/delg/data/gnd_roxford5k.mat \\\n",
        "  --images_dir ./../training/delg/data/oxford5k_images \\\n",
        "  --image_set index \\\n",
        "  --output_features_dir ./../training/delg/data/oxford5k_features/index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHpE_0iXCEaP",
        "outputId": "9edb580f-0bf1-4691-c2c5-254ca8a7cbab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-19 06:35:57.603449: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-19 06:35:57.661466: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-19 06:35:57.673231: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-19 06:36:00.409469: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Reading list of images from dataset file...\n",
            "done! Found 4993 images\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:09.502554 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:09.503068 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:09.503306 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:09.505518 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_variance:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:09.505789 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_variance:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:10.314813 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:10.315083 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:10.315216 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:10.315331 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_variance:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:10.315473 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_variance:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:15.889792 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:15.890064 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:15.890229 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:15.890360 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_variance:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:15.890498 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_variance:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:18.050170 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:18.050477 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:18.050616 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:18.050743 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_variance:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:18.050858 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_variance:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "I1019 06:36:18.161570 133545969942528 load.py:1083] Fingerprint not found. Saved model loading will continue.\n",
            "I1019 06:36:18.161804 133545969942528 load.py:1102] path_and_singleprint metric could not be logged. Saved model loading will continue.\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:21.170290 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:21.170629 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:21.170766 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:21.170876 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_variance:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "W1019 06:36:21.170980 133545969942528 wrap_function.py:208] Unable to create a python object for variable <tf.Variable 'resnet_v1_50/conv1/BatchNorm/moving_variance:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "Starting to extract features...\n",
            "Skipping ashmolean_000283\n",
            "Skipping oxford_002124\n",
            "Skipping radcliffe_camera_000158\n",
            "Skipping oxford_002084\n",
            "Skipping oxford_003332\n",
            "Skipping jesus_000166\n",
            "Skipping oxford_002241\n",
            "Skipping radcliffe_camera_000342\n",
            "Skipping oxford_001431\n",
            "Skipping all_souls_000110\n",
            "Skipping oxford_002729\n",
            "Skipping oxford_002075\n",
            "Skipping new_001014\n",
            "Skipping oriel_000001\n",
            "Skipping oxford_001058\n",
            "Skipping pitt_rivers_000011\n",
            "Skipping christ_church_000406\n",
            "Skipping christ_church_001046\n",
            "Skipping trinity_000015\n",
            "Skipping keble_000005\n",
            "Skipping trinity_000205\n",
            "Skipping oxford_000607\n",
            "Skipping oxford_003393\n",
            "Skipping radcliffe_camera_000560\n",
            "Skipping magdalen_001011\n",
            "Skipping christ_church_000658\n",
            "Skipping new_000921\n",
            "Skipping christ_church_001032\n",
            "Skipping new_000459\n",
            "Skipping radcliffe_camera_000139\n",
            "Skipping all_souls_000153\n",
            "Skipping christ_church_000709\n",
            "Skipping bodleian_000416\n",
            "Skipping magdalen_000386\n",
            "Skipping oxford_001048\n",
            "Skipping oxford_002261\n",
            "Skipping new_000042\n",
            "Skipping magdalen_000643\n",
            "Skipping oxford_001355\n",
            "Skipping bodleian_000120\n",
            "Skipping oxford_003039\n",
            "Skipping christ_church_000380\n",
            "Skipping magdalen_000008\n",
            "Skipping oxford_000825\n",
            "Skipping all_souls_000061\n",
            "Skipping trinity_000287\n",
            "Skipping ashmolean_000217\n",
            "Skipping magdalen_000800\n",
            "Skipping christ_church_000895\n",
            "Skipping christ_church_000644\n",
            "Processing image 50 out of 4993, last 50 images took 6.454459 seconds\n",
            "Skipping oxford_002100\n",
            "Skipping magdalen_000541\n",
            "Skipping oxford_003055\n",
            "Skipping christ_church_000125\n",
            "Skipping oxford_000556\n",
            "Skipping oxford_001725\n",
            "Skipping trinity_000090\n",
            "Skipping oxford_001478\n",
            "Skipping cornmarket_000138\n",
            "Skipping magdalen_000551\n",
            "Skipping oxford_002888\n",
            "Skipping magdalen_000632\n",
            "Skipping worcester_000128\n",
            "Skipping oxford_001889\n",
            "Skipping oxford_000707\n",
            "Skipping jesus_000285\n",
            "Skipping new_001065\n",
            "Skipping radcliffe_camera_000116\n",
            "Skipping oxford_001898\n",
            "Skipping all_souls_000126\n",
            "Skipping trinity_000006\n",
            "Skipping radcliffe_camera_000130\n",
            "Skipping radcliffe_camera_000279\n",
            "Skipping christ_church_000711\n",
            "Skipping oxford_001504\n",
            "Skipping oxford_003180\n",
            "Skipping new_001020\n",
            "Skipping magdalen_000742\n",
            "Skipping new_000374\n",
            "Skipping all_souls_000007\n",
            "Skipping oxford_002236\n",
            "Skipping trinity_000045\n",
            "Skipping oxford_000107\n",
            "Skipping worcester_000194\n",
            "Skipping jesus_000296\n",
            "Skipping jesus_000308\n",
            "Skipping oxford_000167\n",
            "Skipping radcliffe_camera_000337\n",
            "Skipping hertford_000070\n",
            "Skipping radcliffe_camera_000430\n",
            "Skipping radcliffe_camera_000170\n",
            "Skipping christ_church_000239\n",
            "Skipping oxford_000587\n",
            "Skipping magdalen_000343\n",
            "Skipping magdalen_001088\n",
            "Skipping magdalen_000296\n",
            "Skipping magdalen_000576\n",
            "Skipping magdalen_000523\n",
            "Skipping hertford_000083\n",
            "Skipping magdalen_000149\n",
            "Processing image 100 out of 4993, last 50 images took 0.030574 seconds\n",
            "Skipping trinity_000193\n",
            "Skipping oxford_002815\n",
            "Skipping oxford_002308\n",
            "Skipping bodleian_000319\n",
            "Skipping new_000569\n",
            "Skipping oxford_003468\n",
            "Skipping ashmolean_000251\n",
            "Skipping new_000294\n",
            "Skipping oxford_001404\n",
            "Skipping oxford_000681\n",
            "Skipping christ_church_000535\n",
            "Skipping oxford_003505\n",
            "Skipping jesus_000120\n",
            "Skipping oxford_001722\n",
            "Skipping hertford_000106\n",
            "Skipping christ_church_000271\n",
            "Skipping oxford_000768\n",
            "Skipping oxford_001085\n",
            "Skipping cornmarket_000026\n",
            "Skipping new_000630\n",
            "Skipping oxford_000314\n",
            "Skipping oxford_001397\n",
            "Skipping oxford_000160\n",
            "Skipping oxford_002275\n",
            "Skipping bodleian_000135\n",
            "Skipping radcliffe_camera_000234\n",
            "Skipping pitt_rivers_000002\n",
            "Skipping trinity_000031\n",
            "Skipping oxford_003474\n",
            "Skipping radcliffe_camera_000473\n",
            "Skipping oxford_001119\n",
            "Skipping magdalen_000208\n",
            "Skipping oxford_000866\n",
            "Skipping oxford_002672\n",
            "Skipping magdalen_000297\n",
            "Skipping new_000949\n",
            "Skipping oxford_001882\n",
            "Skipping oriel_000083\n",
            "Skipping balliol_000169\n",
            "Skipping oxford_001527\n",
            "Skipping oxford_003542\n",
            "Skipping magdalen_000542\n",
            "Skipping new_000409\n",
            "Skipping oxford_001282\n",
            "Skipping jesus_000295\n",
            "Skipping cornmarket_000061\n",
            "Skipping oxford_000413\n",
            "Skipping ashmolean_000255\n",
            "Skipping oxford_000055\n",
            "Skipping radcliffe_camera_000305\n",
            "Processing image 150 out of 4993, last 50 images took 0.032205 seconds\n",
            "Skipping balliol_000110\n",
            "Skipping pitt_rivers_000143\n",
            "Skipping cornmarket_000039\n",
            "Skipping oxford_002819\n",
            "Skipping bodleian_000019\n",
            "Skipping magdalen_000312\n",
            "Skipping trinity_000364\n",
            "Skipping new_000642\n",
            "Skipping christ_church_000804\n",
            "Skipping magdalen_000864\n",
            "Skipping oxford_001270\n",
            "Skipping oriel_000113\n",
            "Skipping oriel_000091\n",
            "Skipping oxford_000620\n",
            "Skipping radcliffe_camera_000345\n",
            "Skipping oxford_000281\n",
            "Skipping ashmolean_000307\n",
            "Skipping keble_000168\n",
            "Skipping keble_000004\n",
            "Skipping keble_000241\n",
            "Skipping new_000453\n",
            "Skipping oxford_003025\n",
            "Skipping magdalen_000174\n",
            "Skipping magdalen_000180\n",
            "Skipping oxford_003263\n",
            "Skipping christ_church_000672\n",
            "Skipping all_souls_000018\n",
            "Skipping magdalen_000172\n",
            "Skipping new_000881\n",
            "Skipping balliol_000151\n",
            "Skipping oxford_000917\n",
            "Skipping oxford_003182\n",
            "Skipping magdalen_000538\n",
            "Skipping radcliffe_camera_000326\n",
            "Skipping oxford_001071\n",
            "Skipping all_souls_000062\n",
            "Skipping new_000739\n",
            "Skipping christ_church_000138\n",
            "Skipping oxford_001309\n",
            "Skipping jesus_000245\n",
            "Skipping christ_church_000307\n",
            "Skipping christ_church_000163\n",
            "Skipping jesus_000333\n",
            "Skipping magdalen_001157\n",
            "Skipping oxford_003597\n",
            "Skipping christ_church_000268\n",
            "Skipping magdalen_000534\n",
            "Skipping oxford_002580\n",
            "Skipping oxford_001654\n",
            "Skipping oxford_000056\n",
            "Processing image 200 out of 4993, last 50 images took 0.030335 seconds\n",
            "Skipping oxford_003279\n",
            "Skipping oxford_003137\n",
            "Skipping christ_church_000721\n",
            "Skipping oxford_001413\n",
            "Skipping oxford_002193\n",
            "Skipping christ_church_000371\n",
            "Skipping bodleian_000386\n",
            "Skipping keble_000027\n",
            "Skipping magdalen_000591\n",
            "Skipping magdalen_000550\n",
            "Skipping oxford_001879\n",
            "Skipping ashmolean_000196\n",
            "Skipping magdalen_000034\n",
            "Skipping pitt_rivers_000014\n",
            "Skipping magdalen_000449\n",
            "Skipping magdalen_000299\n",
            "Skipping oxford_002422\n",
            "Skipping magdalen_001001\n",
            "Skipping new_000391\n",
            "Skipping new_000088\n",
            "Skipping oxford_003006\n",
            "Skipping trinity_000173\n",
            "Skipping new_000008\n",
            "Skipping new_001090\n",
            "Skipping new_001082\n",
            "Skipping christ_church_000632\n",
            "Skipping magdalen_000751\n",
            "Skipping bodleian_000351\n",
            "Skipping oxford_001173\n",
            "Skipping oriel_000002\n",
            "Skipping magdalen_000713\n",
            "Skipping jesus_000025\n",
            "Skipping all_souls_000060\n",
            "Skipping bodleian_000294\n",
            "Skipping christ_church_000324\n",
            "Skipping christ_church_000602\n",
            "Skipping oriel_000007\n",
            "Skipping worcester_000121\n",
            "Skipping new_001057\n",
            "Skipping oxford_002482\n",
            "Skipping keble_000042\n",
            "Skipping oxford_002373\n",
            "Skipping oxford_002344\n",
            "Skipping magdalen_000451\n",
            "Skipping magdalen_001147\n",
            "Skipping trinity_000310\n",
            "Skipping magdalen_000308\n",
            "Skipping balliol_000035\n",
            "Skipping radcliffe_camera_000295\n",
            "Skipping oxford_002238\n",
            "Processing image 250 out of 4993, last 50 images took 0.030586 seconds\n",
            "Skipping new_000810\n",
            "Skipping bodleian_000207\n",
            "Skipping radcliffe_camera_000530\n",
            "Skipping oxford_000318\n",
            "Skipping oxford_001803\n",
            "Skipping new_000951\n",
            "Skipping radcliffe_camera_000258\n",
            "Skipping christ_church_000269\n",
            "Skipping radcliffe_camera_000426\n",
            "Skipping ashmolean_000090\n",
            "Skipping oxford_001750\n",
            "Skipping oxford_003506\n",
            "Skipping christ_church_001019\n",
            "Skipping christ_church_000989\n",
            "Skipping trinity_000058\n",
            "Skipping oxford_000259\n",
            "Skipping christ_church_000160\n",
            "Skipping oxford_003341\n",
            "Skipping keble_000032\n",
            "Skipping jesus_000294\n",
            "Skipping oriel_000074\n",
            "Skipping balliol_000136\n",
            "Skipping oxford_001833\n",
            "Skipping magdalen_000595\n",
            "Skipping magdalen_000875\n",
            "Skipping oxford_001567\n",
            "Skipping christ_church_000430\n",
            "Skipping oxford_000865\n",
            "Skipping bodleian_000000\n",
            "Skipping magdalen_000274\n",
            "Skipping radcliffe_camera_000113\n",
            "Skipping oxford_001122\n",
            "Skipping oxford_003248\n",
            "Skipping ashmolean_000213\n",
            "Skipping new_000905\n",
            "Skipping magdalen_000141\n",
            "Skipping ashmolean_000232\n",
            "Skipping new_001048\n",
            "Skipping oxford_001770\n",
            "Skipping oxford_000522\n",
            "Skipping christ_church_000339\n",
            "Skipping radcliffe_camera_000155\n",
            "Skipping ashmolean_000201\n",
            "Skipping oxford_001356\n",
            "Skipping worcester_000198\n",
            "Skipping oxford_002639\n",
            "Skipping all_souls_000055\n",
            "Skipping christ_church_000920\n",
            "Skipping keble_000188\n",
            "Skipping ashmolean_000273\n",
            "Processing image 300 out of 4993, last 50 images took 0.034996 seconds\n",
            "Skipping new_000979\n",
            "Skipping magdalen_000229\n",
            "Skipping ashmolean_000224\n",
            "Skipping new_000421\n",
            "Skipping oxford_002351\n",
            "Skipping christ_church_001022\n",
            "Skipping oxford_003060\n",
            "Skipping oxford_003453\n",
            "Skipping oxford_001360\n",
            "Skipping christ_church_000310\n",
            "Skipping christ_church_000144\n",
            "Skipping bodleian_000303\n",
            "Skipping trinity_000017\n",
            "Skipping oxford_002375\n",
            "Skipping bodleian_000085\n",
            "Skipping magdalen_000679\n",
            "Skipping christ_church_000844\n",
            "Skipping christ_church_000416\n",
            "Skipping oxford_002089\n",
            "Skipping keble_000207\n",
            "Skipping pitt_rivers_000137\n",
            "Skipping christ_church_000446\n",
            "Skipping oxford_002145\n",
            "Skipping christ_church_001094\n",
            "Skipping oxford_000130\n",
            "Skipping oxford_001508\n",
            "Skipping radcliffe_camera_000103\n",
            "Skipping oxford_001443\n",
            "Skipping trinity_000024\n",
            "Skipping new_001097\n",
            "Skipping oxford_002908\n",
            "Skipping worcester_000075\n",
            "Skipping oxford_002171\n",
            "Skipping oxford_002733\n",
            "Skipping trinity_000302\n",
            "Skipping ashmolean_000229\n",
            "Skipping oriel_000121\n",
            "Skipping jesus_000134\n",
            "Skipping magdalen_000943\n",
            "Skipping all_souls_000044\n",
            "Skipping pitt_rivers_000017\n",
            "Skipping new_000199\n",
            "Skipping radcliffe_camera_000410\n",
            "Skipping jesus_000292\n",
            "Skipping oxford_003569\n",
            "Skipping oxford_000091\n",
            "Skipping oxford_002500\n",
            "Skipping oxford_002357\n",
            "Skipping oxford_002539\n",
            "Skipping ashmolean_000125\n",
            "Processing image 350 out of 4993, last 50 images took 0.032886 seconds\n",
            "Skipping radcliffe_camera_000283\n",
            "Skipping keble_000047\n",
            "Skipping radcliffe_camera_000439\n",
            "Skipping new_000325\n",
            "Skipping magdalen_000178\n",
            "Skipping all_souls_000186\n",
            "Skipping keble_000023\n",
            "Skipping trinity_000371\n",
            "Skipping oxford_002307\n",
            "Skipping oxford_003343\n",
            "Skipping balliol_000057\n",
            "Skipping oxford_000869\n",
            "Skipping oxford_000414\n",
            "Skipping jesus_000038\n",
            "Skipping oxford_001193\n",
            "Skipping magdalen_000073\n",
            "Skipping magdalen_000072\n",
            "Skipping worcester_000122\n",
            "Skipping ashmolean_000150\n",
            "Skipping magdalen_000545\n",
            "Skipping magdalen_000495\n",
            "Skipping bodleian_000187\n",
            "Skipping oxford_001829\n",
            "Skipping oxford_003407\n",
            "Skipping oxford_002007\n",
            "Skipping christ_church_000049\n",
            "Skipping ashmolean_000209\n",
            "Skipping oxford_002517\n",
            "Skipping new_000904\n",
            "Skipping new_000136\n",
            "Skipping trinity_000225\n",
            "Skipping all_souls_000142\n",
            "Skipping magdalen_000002\n",
            "Skipping oxford_003478\n",
            "Skipping oxford_000457\n",
            "Skipping bodleian_000320\n",
            "Skipping oxford_001480\n",
            "Skipping oxford_001167\n",
            "Skipping oxford_002977\n",
            "Skipping oxford_003009\n",
            "Skipping christ_church_000956\n",
            "Skipping keble_000021\n",
            "Skipping christ_church_000408\n",
            "Skipping oxford_000188\n",
            "Skipping christ_church_000836\n",
            "Skipping oxford_002243\n",
            "Skipping oxford_003328\n",
            "Skipping oxford_002355\n",
            "Skipping new_000004\n",
            "Skipping magdalen_000144\n",
            "Processing image 400 out of 4993, last 50 images took 0.031297 seconds\n",
            "Skipping christ_church_000374\n",
            "Skipping oxford_001922\n",
            "Skipping new_000746\n",
            "Skipping all_souls_000028\n",
            "Skipping magdalen_000942\n",
            "Skipping oxford_001789\n",
            "Skipping magdalen_000365\n",
            "Skipping oxford_002860\n",
            "Skipping oxford_001427\n",
            "Skipping hertford_000073\n",
            "Skipping new_000370\n",
            "Skipping new_000026\n",
            "Skipping balliol_000213\n",
            "Skipping oxford_001636\n",
            "Skipping magdalen_001032\n",
            "Skipping oxford_003513\n",
            "Skipping bodleian_000238\n",
            "Skipping keble_000070\n",
            "Skipping magdalen_000747\n",
            "Skipping oriel_000022\n",
            "Skipping oxford_001751\n",
            "Skipping magdalen_001014\n",
            "Skipping oxford_003657\n",
            "Skipping ashmolean_000148\n",
            "Skipping trinity_000001\n",
            "Skipping oxford_000377\n",
            "Skipping balliol_000097\n",
            "Skipping bodleian_000070\n",
            "Skipping christ_church_000762\n",
            "Skipping radcliffe_camera_000172\n",
            "Skipping oxford_002518\n",
            "Skipping oxford_002470\n",
            "Skipping oxford_000753\n",
            "Skipping ashmolean_000220\n",
            "Skipping jesus_000099\n",
            "Skipping bodleian_000016\n",
            "Skipping all_souls_000130\n",
            "Skipping christ_church_000400\n",
            "Skipping oxford_000705\n",
            "Skipping trinity_000040\n",
            "Skipping oxford_003135\n",
            "Skipping magdalen_000332\n",
            "Skipping bodleian_000246\n",
            "Skipping trinity_000335\n",
            "Skipping christ_church_000539\n",
            "Skipping oxford_003515\n",
            "Skipping radcliffe_camera_000269\n",
            "Skipping oxford_002905\n",
            "Skipping oxford_003647\n",
            "Skipping ashmolean_000122\n",
            "Processing image 450 out of 4993, last 50 images took 0.033680 seconds\n",
            "Skipping jesus_000014\n",
            "Skipping oxford_000138\n",
            "Skipping bodleian_000116\n",
            "Skipping oxford_002667\n",
            "Skipping oxford_000610\n",
            "Skipping oxford_000902\n",
            "Skipping oxford_000901\n",
            "Skipping new_000884\n",
            "Skipping cornmarket_000107\n",
            "Skipping trinity_000319\n",
            "Skipping oxford_000626\n",
            "Skipping all_souls_000012\n",
            "Skipping oxford_001710\n",
            "Skipping magdalen_000618\n",
            "Skipping christ_church_000418\n",
            "Skipping oxford_002646\n",
            "Skipping balliol_000191\n",
            "Skipping new_000725\n",
            "Skipping new_001112\n",
            "Skipping magdalen_000528\n",
            "Skipping oxford_003179\n",
            "Skipping magdalen_000992\n",
            "Skipping christ_church_000059\n",
            "Skipping oxford_000574\n",
            "Skipping oxford_000114\n",
            "Skipping oxford_001359\n",
            "Skipping magdalen_000266\n",
            "Skipping bodleian_000232\n",
            "Skipping new_000185\n",
            "Skipping keble_000038\n",
            "Skipping oxford_002036\n",
            "Skipping oxford_002839\n",
            "Skipping oxford_000082\n",
            "Skipping radcliffe_camera_000362\n",
            "Skipping magdalen_000247\n",
            "Skipping worcester_000069\n",
            "Skipping jesus_000357\n",
            "Skipping oxford_003235\n",
            "Skipping trinity_000321\n",
            "Skipping oxford_000637\n",
            "Skipping new_001094\n",
            "Skipping christ_church_000626\n",
            "Skipping new_000805\n",
            "Skipping ashmolean_000262\n",
            "Skipping oxford_000296\n",
            "Skipping all_souls_000162\n",
            "Skipping bodleian_000378\n",
            "Skipping new_000223\n",
            "Skipping magdalen_000702\n",
            "Skipping oxford_002951\n",
            "Processing image 500 out of 4993, last 50 images took 0.033817 seconds\n",
            "Skipping pitt_rivers_000142\n",
            "Skipping balliol_000103\n",
            "Skipping bodleian_000014\n",
            "Skipping all_souls_000027\n",
            "Skipping bodleian_000425\n",
            "Skipping ashmolean_000179\n",
            "Skipping christ_church_000222\n",
            "Skipping radcliffe_camera_000015\n",
            "Skipping radcliffe_camera_000463\n",
            "Skipping keble_000126\n",
            "Skipping ashmolean_000116\n",
            "Skipping all_souls_000220\n",
            "Skipping pitt_rivers_000077\n",
            "Skipping new_000164\n",
            "Skipping christ_church_000414\n",
            "Skipping oxford_001436\n",
            "Skipping bodleian_000405\n",
            "Skipping christ_church_000661\n",
            "Skipping oxford_000487\n",
            "Skipping hertford_000035\n",
            "Skipping magdalen_001007\n",
            "Skipping ashmolean_000174\n",
            "Skipping christ_church_001062\n",
            "Skipping oxford_003095\n",
            "Skipping trinity_000227\n",
            "Skipping oriel_000102\n",
            "Skipping oxford_003482\n",
            "Skipping christ_church_000288\n",
            "Skipping new_000731\n",
            "Skipping balliol_000056\n",
            "Skipping new_000877\n",
            "Skipping magdalen_000202\n",
            "Skipping oxford_002174\n",
            "Skipping oxford_000975\n",
            "Skipping oxford_000374\n",
            "Skipping oxford_000699\n",
            "Skipping balliol_000013\n",
            "Skipping magdalen_001119\n",
            "Skipping new_000475\n",
            "Skipping radcliffe_camera_000301\n",
            "Skipping radcliffe_camera_000456\n",
            "Skipping balliol_000054\n",
            "Skipping magdalen_000224\n",
            "Skipping oxford_001139\n",
            "Skipping magdalen_000582\n",
            "Skipping oxford_001905\n",
            "Skipping magdalen_000727\n",
            "Skipping christ_church_001149\n",
            "Skipping oxford_003681\n",
            "Skipping christ_church_000279\n",
            "Processing image 550 out of 4993, last 50 images took 0.030740 seconds\n",
            "Skipping keble_000062\n",
            "Skipping oxford_000011\n",
            "Skipping christ_church_000424\n",
            "Skipping magdalen_001055\n",
            "Skipping oxford_002896\n",
            "Skipping ashmolean_000244\n",
            "Skipping oxford_003178\n",
            "Skipping jesus_000315\n",
            "Skipping ashmolean_000003\n",
            "Skipping oxford_001175\n",
            "Skipping jesus_000003\n",
            "Skipping oxford_000010\n",
            "Skipping radcliffe_camera_000094\n",
            "Skipping pitt_rivers_000146\n",
            "Skipping radcliffe_camera_000107\n",
            "Skipping oxford_002198\n",
            "Skipping christ_church_000361\n",
            "Skipping magdalen_000276\n",
            "Skipping oxford_000708\n",
            "Skipping bodleian_000328\n",
            "Skipping radcliffe_camera_000239\n",
            "Skipping magdalen_000165\n",
            "Skipping magdalen_000245\n",
            "Skipping oxford_002662\n",
            "Skipping oxford_001649\n",
            "Skipping oxford_001341\n",
            "Skipping bodleian_000025\n",
            "Skipping oxford_001382\n",
            "Skipping oxford_002319\n",
            "Skipping christ_church_000542\n",
            "Skipping oxford_003403\n",
            "Skipping all_souls_000091\n",
            "Skipping trinity_000237\n",
            "Skipping oxford_002279\n",
            "Skipping trinity_000130\n",
            "Skipping oxford_000741\n",
            "Skipping magdalen_000645\n",
            "Skipping magdalen_000282\n",
            "Skipping oxford_000752\n",
            "Skipping jesus_000122\n",
            "Skipping oxford_003366\n",
            "Skipping christ_church_000304\n",
            "Skipping all_souls_000120\n",
            "Skipping oxford_000579\n",
            "Skipping new_000646\n",
            "Skipping oxford_000704\n",
            "Skipping oxford_003299\n",
            "Skipping new_000860\n",
            "Skipping balliol_000039\n",
            "Skipping magdalen_001094\n",
            "Processing image 600 out of 4993, last 50 images took 0.031360 seconds\n",
            "Skipping jesus_000056\n",
            "Skipping magdalen_001008\n",
            "Skipping christ_church_000758\n",
            "Skipping magdalen_001060\n",
            "Skipping oriel_000106\n",
            "Skipping oxford_000636\n",
            "Skipping oxford_000423\n",
            "Skipping balliol_000066\n",
            "Skipping balliol_000119\n",
            "Skipping new_000811\n",
            "Skipping oxford_002499\n",
            "Skipping magdalen_000005\n",
            "Skipping magdalen_000803\n",
            "Skipping magdalen_000520\n",
            "Skipping oxford_001152\n",
            "Skipping new_000108\n",
            "Skipping all_souls_000219\n",
            "Skipping oxford_002190\n",
            "Skipping oxford_002361\n",
            "Skipping oxford_003015\n",
            "Skipping cornmarket_000065\n",
            "Skipping radcliffe_camera_000416\n",
            "Skipping bodleian_000324\n",
            "Skipping all_souls_000073\n",
            "Skipping magdalen_000826\n",
            "Skipping magdalen_000748\n",
            "Skipping keble_000093\n",
            "Skipping new_000613\n",
            "Skipping christ_church_000319\n",
            "Skipping christ_church_000976\n",
            "Skipping new_000961\n",
            "Skipping christ_church_000718\n",
            "Skipping oxford_000019\n",
            "Skipping magdalen_000316\n",
            "Skipping magdalen_000187\n",
            "Skipping magdalen_000508\n",
            "Skipping trinity_000069\n",
            "Skipping christ_church_000316\n",
            "Skipping pitt_rivers_000112\n",
            "Skipping balliol_000079\n",
            "Skipping oxford_002077\n",
            "Skipping radcliffe_camera_000104\n",
            "Skipping oxford_003383\n",
            "Skipping oxford_001535\n",
            "Skipping oxford_001556\n",
            "Skipping oxford_002066\n",
            "Skipping christ_church_000224\n",
            "Skipping oxford_001190\n",
            "Skipping radcliffe_camera_000187\n",
            "Skipping jesus_000037\n",
            "Processing image 650 out of 4993, last 50 images took 0.041044 seconds\n",
            "Skipping oxford_000068\n",
            "Skipping oxford_002530\n",
            "Skipping magdalen_000871\n",
            "Skipping oxford_000389\n",
            "Skipping new_000983\n",
            "Skipping christ_church_000619\n",
            "Skipping oxford_000588\n",
            "Skipping christ_church_000353\n",
            "Skipping magdalen_000485\n",
            "Skipping pitt_rivers_000126\n",
            "Skipping oxford_002762\n",
            "Skipping magdalen_000186\n",
            "Skipping trinity_000226\n",
            "Skipping oxford_000087\n",
            "Skipping christ_church_001078\n",
            "Skipping oxford_003035\n",
            "Skipping oxford_000709\n",
            "Skipping jesus_000286\n",
            "Skipping oxford_001721\n",
            "Skipping oxford_001728\n",
            "Skipping oxford_000316\n",
            "Skipping oxford_001411\n",
            "Skipping magdalen_001143\n",
            "Skipping christ_church_000419\n",
            "Skipping oxford_000658\n",
            "Skipping new_000668\n",
            "Skipping trinity_000282\n",
            "Skipping ashmolean_000169\n",
            "Skipping oxford_000504\n",
            "Skipping keble_000164\n",
            "Skipping ashmolean_000231\n",
            "Skipping magdalen_001145\n",
            "Skipping ashmolean_000230\n",
            "Skipping radcliffe_camera_000296\n",
            "Skipping oxford_003331\n",
            "Skipping oxford_000177\n",
            "Skipping oxford_000169\n",
            "Skipping oxford_000560\n",
            "Skipping pitt_rivers_000163\n",
            "Skipping christ_church_000630\n",
            "Skipping oxford_002508\n",
            "Skipping all_souls_000001\n",
            "Skipping pitt_rivers_000194\n",
            "Skipping oxford_002547\n",
            "Skipping christ_church_000396\n",
            "Skipping oxford_001406\n",
            "Skipping cornmarket_000041\n",
            "Skipping pitt_rivers_000042\n",
            "Skipping christ_church_000002\n",
            "Skipping new_000741\n",
            "Processing image 700 out of 4993, last 50 images took 0.036189 seconds\n",
            "Skipping magdalen_000325\n",
            "Skipping keble_000102\n",
            "Skipping balliol_000024\n",
            "Skipping magdalen_000526\n",
            "Skipping jesus_000394\n",
            "Skipping magdalen_000177\n",
            "Skipping oxford_003627\n",
            "Skipping new_000407\n",
            "Skipping bodleian_000258\n",
            "Skipping christ_church_000136\n",
            "Skipping new_001036\n",
            "Skipping oxford_002898\n",
            "Skipping oxford_003183\n",
            "Skipping jesus_000288\n",
            "Skipping magdalen_000436\n",
            "Skipping oxford_000570\n",
            "Skipping christ_church_001017\n",
            "Skipping jesus_000186\n",
            "Skipping magdalen_000248\n",
            "Skipping oxford_000605\n",
            "Skipping bodleian_000408\n",
            "Skipping pitt_rivers_000139\n",
            "Skipping oxford_002202\n",
            "Skipping oxford_001107\n",
            "Skipping oxford_002265\n",
            "Skipping magdalen_000761\n",
            "Skipping new_000964\n",
            "Skipping magdalen_000210\n",
            "Skipping cornmarket_000022\n",
            "Skipping oxford_002144\n",
            "Skipping oriel_000071\n",
            "Skipping christ_church_000263\n",
            "Skipping new_000686\n",
            "Skipping oxford_002347\n",
            "Skipping christ_church_000164\n",
            "Skipping oxford_000079\n",
            "Skipping all_souls_000064\n",
            "Skipping oxford_001154\n",
            "Skipping christ_church_000682\n",
            "Skipping oxford_000289\n",
            "Skipping radcliffe_camera_000298\n",
            "Skipping magdalen_000198\n",
            "Skipping christ_church_000641\n",
            "Skipping bodleian_000148\n",
            "Skipping magdalen_000290\n",
            "Skipping pitt_rivers_000120\n",
            "Skipping bodleian_000325\n",
            "Skipping magdalen_000377\n",
            "Skipping new_000900\n",
            "Skipping magdalen_000608\n",
            "Processing image 750 out of 4993, last 50 images took 0.039522 seconds\n",
            "Skipping oxford_003466\n",
            "Skipping oxford_003642\n",
            "Skipping keble_000108\n",
            "Skipping oxford_003122\n",
            "Skipping magdalen_000228\n",
            "Skipping jesus_000353\n",
            "Skipping christ_church_000177\n",
            "Skipping trinity_000008\n",
            "Skipping oxford_001877\n",
            "Skipping ashmolean_000149\n",
            "Skipping oxford_000884\n",
            "Skipping jesus_000398\n",
            "Skipping oxford_002870\n",
            "Skipping hertford_000011\n",
            "Skipping radcliffe_camera_000373\n",
            "Skipping oxford_000878\n",
            "Skipping christ_church_000870\n",
            "Skipping trinity_000128\n",
            "Skipping radcliffe_camera_000289\n",
            "Skipping magdalen_000338\n",
            "Skipping hertford_000133\n",
            "Skipping new_000820\n",
            "Skipping magdalen_000677\n",
            "Skipping keble_000233\n",
            "Skipping pitt_rivers_000129\n",
            "Skipping trinity_000125\n",
            "Skipping christ_church_000382\n",
            "Skipping oxford_001344\n",
            "Skipping oxford_001007\n",
            "Skipping keble_000014\n",
            "Skipping new_000339\n",
            "Skipping bodleian_000420\n",
            "Skipping oxford_000220\n",
            "Skipping jesus_000215\n",
            "Skipping hertford_000056\n",
            "Skipping oxford_002591\n",
            "Skipping trinity_000382\n",
            "Skipping oxford_001764\n",
            "Skipping magdalen_001027\n",
            "Skipping oxford_000933\n",
            "Skipping bodleian_000301\n",
            "Skipping keble_000081\n",
            "Skipping keble_000192\n",
            "Skipping oxford_002920\n",
            "Skipping worcester_000137\n",
            "Skipping oxford_000728\n",
            "Skipping radcliffe_camera_000215\n",
            "Skipping oxford_001724\n",
            "Skipping oxford_003329\n",
            "Skipping oxford_003382\n",
            "Processing image 800 out of 4993, last 50 images took 0.035209 seconds\n",
            "Skipping oxford_002880\n",
            "Skipping oxford_000926\n",
            "Skipping radcliffe_camera_000217\n",
            "Skipping oxford_002031\n",
            "Skipping bodleian_000037\n",
            "Skipping oxford_001274\n",
            "Skipping oriel_000014\n",
            "Skipping oxford_000742\n",
            "Skipping jesus_000053\n",
            "Skipping magdalen_000361\n",
            "Skipping oxford_001707\n",
            "Skipping oriel_000088\n",
            "Skipping christ_church_000792\n",
            "Skipping christ_church_001025\n",
            "Skipping oxford_003553\n",
            "Skipping christ_church_001028\n",
            "Skipping oxford_000967\n",
            "Skipping trinity_000068\n",
            "Skipping oxford_001583\n",
            "Skipping trinity_000169\n",
            "Skipping christ_church_000357\n",
            "Skipping new_000866\n",
            "Skipping oxford_001064\n",
            "Skipping magdalen_000993\n",
            "Skipping oxford_001775\n",
            "Skipping bodleian_000017\n",
            "Skipping new_000170\n",
            "Skipping oxford_000018\n",
            "Skipping oxford_003656\n",
            "Skipping magdalen_000860\n",
            "Skipping christ_church_000435\n",
            "Skipping radcliffe_camera_000080\n",
            "Skipping oxford_003007\n",
            "Skipping balliol_000098\n",
            "Skipping new_000197\n",
            "Skipping trinity_000195\n",
            "Skipping christ_church_000627\n",
            "Skipping new_000057\n",
            "Skipping oxford_001195\n",
            "Skipping jesus_000124\n",
            "Skipping new_000699\n",
            "Skipping christ_church_000584\n",
            "Skipping magdalen_000511\n",
            "Skipping new_000474\n",
            "Skipping ashmolean_000316\n",
            "Skipping balliol_000117\n",
            "Skipping new_000986\n",
            "Skipping trinity_000039\n",
            "Skipping trinity_000363\n",
            "Skipping magdalen_001034\n",
            "Processing image 850 out of 4993, last 50 images took 0.032820 seconds\n",
            "Skipping new_000251\n",
            "Skipping trinity_000072\n",
            "Skipping oxford_003464\n",
            "Skipping pitt_rivers_000074\n",
            "Skipping bodleian_000021\n",
            "Skipping keble_000244\n",
            "Skipping worcester_000133\n",
            "Skipping balliol_000147\n",
            "Skipping oxford_001716\n",
            "Skipping ashmolean_000279\n",
            "Skipping jesus_000332\n",
            "Skipping oxford_001927\n",
            "Skipping oxford_000858\n",
            "Skipping new_000393\n",
            "Skipping bodleian_000375\n",
            "Skipping magdalen_000519\n",
            "Skipping magdalen_000990\n",
            "Skipping oxford_003409\n",
            "Skipping christ_church_001083\n",
            "Skipping trinity_000262\n",
            "Skipping bodleian_000471\n",
            "Skipping oxford_000238\n",
            "Skipping oxford_000960\n",
            "Skipping ashmolean_000345\n",
            "Skipping oxford_001291\n",
            "Skipping christ_church_000892\n",
            "Skipping oxford_001650\n",
            "Skipping worcester_000119\n",
            "Skipping oxford_003450\n",
            "Skipping magdalen_000760\n",
            "Skipping new_000056\n",
            "Skipping oxford_001278\n",
            "Skipping christ_church_000143\n",
            "Skipping oxford_000683\n",
            "Skipping magdalen_000188\n",
            "Skipping cornmarket_000071\n",
            "Skipping radcliffe_camera_000016\n",
            "Skipping magdalen_000954\n",
            "Skipping ashmolean_000211\n",
            "Skipping magdalen_000047\n",
            "Skipping pitt_rivers_000132\n",
            "Skipping christ_church_000975\n",
            "Skipping balliol_000118\n",
            "Skipping oxford_000012\n",
            "Skipping balliol_000144\n",
            "Skipping bodleian_000050\n",
            "Skipping magdalen_000136\n",
            "Skipping oxford_003205\n",
            "Skipping new_000728\n",
            "Skipping radcliffe_camera_000324\n",
            "Processing image 900 out of 4993, last 50 images took 0.029487 seconds\n",
            "Skipping magdalen_000133\n",
            "Skipping oxford_003268\n",
            "Skipping trinity_000026\n",
            "Skipping oxford_003170\n",
            "Skipping balliol_000095\n",
            "Skipping bodleian_000198\n",
            "Skipping magdalen_000506\n",
            "Skipping cornmarket_000020\n",
            "Skipping oriel_000041\n",
            "Skipping oxford_003294\n",
            "Skipping radcliffe_camera_000364\n",
            "Skipping hertford_000017\n",
            "Skipping bodleian_000291\n",
            "Skipping jesus_000336\n",
            "Skipping oxford_002801\n",
            "Skipping new_000814\n",
            "Skipping new_000050\n",
            "Skipping worcester_000055\n",
            "Skipping radcliffe_camera_000478\n",
            "Skipping pitt_rivers_000010\n",
            "Skipping oxford_001961\n",
            "Skipping jesus_000283\n",
            "Skipping oxford_000984\n",
            "Skipping balliol_000026\n",
            "Skipping worcester_000062\n",
            "Skipping radcliffe_camera_000390\n",
            "Skipping oriel_000033\n",
            "Skipping christ_church_000402\n",
            "Skipping balliol_000060\n",
            "Skipping magdalen_000703\n",
            "Skipping trinity_000131\n",
            "Skipping new_000687\n",
            "Skipping oxford_001895\n",
            "Skipping oxford_002841\n",
            "Skipping new_000275\n",
            "Skipping magdalen_001149\n",
            "Skipping oriel_000003\n",
            "Skipping oxford_000110\n",
            "Skipping oxford_000041\n",
            "Skipping magdalen_000349\n",
            "Skipping keble_000088\n",
            "Skipping christ_church_000623\n",
            "Skipping magdalen_001059\n",
            "Skipping oxford_001867\n",
            "Skipping christ_church_000897\n",
            "Skipping radcliffe_camera_000429\n",
            "Skipping oxford_000565\n",
            "Skipping hertford_000081\n",
            "Skipping christ_church_000987\n",
            "Skipping christ_church_000215\n",
            "Processing image 950 out of 4993, last 50 images took 0.036341 seconds\n",
            "Skipping oxford_002183\n",
            "Skipping christ_church_000377\n",
            "Skipping magdalen_001063\n",
            "Skipping hertford_000039\n",
            "Skipping bodleian_000062\n",
            "Skipping trinity_000290\n",
            "Skipping jesus_000117\n",
            "Skipping magdalen_000979\n",
            "Skipping jesus_000328\n",
            "Skipping oxford_003067\n",
            "Skipping magdalen_001021\n",
            "Skipping oriel_000078\n",
            "Skipping trinity_000049\n",
            "Skipping oxford_001672\n",
            "Skipping christ_church_000545\n",
            "Skipping oxford_000422\n",
            "Skipping radcliffe_camera_000160\n",
            "Skipping magdalen_000359\n",
            "Skipping oxford_001506\n",
            "Skipping ashmolean_000303\n",
            "Skipping magdalen_000132\n",
            "Skipping christ_church_000170\n",
            "Skipping hertford_000116\n",
            "Skipping magdalen_000862\n",
            "Skipping magdalen_000655\n",
            "Skipping radcliffe_camera_000292\n",
            "Skipping oriel_000046\n",
            "Skipping jesus_000330\n",
            "Skipping oxford_000100\n",
            "Skipping ashmolean_000214\n",
            "Skipping oxford_003156\n",
            "Skipping magdalen_001144\n",
            "Skipping oxford_001717\n",
            "Skipping oxford_003576\n",
            "Skipping balliol_000052\n",
            "Skipping balliol_000156\n",
            "Skipping pitt_rivers_000128\n",
            "Skipping new_000978\n",
            "Skipping trinity_000336\n",
            "Skipping oxford_000877\n",
            "Skipping oxford_001396\n",
            "Skipping radcliffe_camera_000100\n",
            "Skipping christ_church_000379\n",
            "Skipping christ_church_000815\n",
            "Skipping oxford_002158\n",
            "Skipping magdalen_000614\n",
            "Skipping radcliffe_camera_000092\n",
            "Skipping christ_church_000900\n",
            "Skipping magdalen_000041\n",
            "Skipping christ_church_001070\n",
            "Processing image 1000 out of 4993, last 50 images took 0.028479 seconds\n",
            "Skipping jesus_000350\n",
            "Skipping new_000690\n",
            "Skipping oxford_001186\n",
            "Skipping hertford_000024\n",
            "Skipping all_souls_000000\n",
            "Skipping christ_church_001113\n",
            "Skipping christ_church_000434\n",
            "Skipping oxford_001960\n",
            "Skipping oxford_003632\n",
            "Skipping hertford_000091\n",
            "Skipping magdalen_000006\n",
            "Skipping new_001047\n",
            "Skipping oxford_003520\n",
            "Skipping oxford_001541\n",
            "Skipping oxford_000179\n",
            "Skipping new_001004\n",
            "Skipping oxford_000530\n",
            "Skipping ashmolean_000228\n",
            "Skipping radcliffe_camera_000248\n",
            "Skipping radcliffe_camera_000036\n",
            "Skipping new_001030\n",
            "Skipping balliol_000018\n",
            "Skipping cornmarket_000077\n",
            "Skipping trinity_000030\n",
            "Skipping keble_000202\n",
            "Skipping magdalen_001064\n",
            "Skipping new_000318\n",
            "Processing image 1050 out of 4993, last 50 images took 435.031786 seconds\n",
            "Processing image 1100 out of 4993, last 50 images took 928.598111 seconds\n",
            "Processing image 1150 out of 4993, last 50 images took 932.413930 seconds\n",
            "Processing image 1200 out of 4993, last 50 images took 924.667851 seconds\n",
            "Processing image 1250 out of 4993, last 50 images took 919.342601 seconds\n",
            "Processing image 1300 out of 4993, last 50 images took 928.974686 seconds\n",
            "Processing image 1350 out of 4993, last 50 images took 913.276894 seconds\n",
            "Processing image 1400 out of 4993, last 50 images took 908.668372 seconds\n",
            "Processing image 1450 out of 4993, last 50 images took 922.467840 seconds\n",
            "Processing image 1500 out of 4993, last 50 images took 893.124119 seconds\n",
            "Processing image 1550 out of 4993, last 50 images took 902.950680 seconds\n",
            "Processing image 1600 out of 4993, last 50 images took 896.027258 seconds\n",
            "Processing image 1650 out of 4993, last 50 images took 877.855422 seconds\n",
            "Processing image 1700 out of 4993, last 50 images took 877.205523 seconds\n",
            "Processing image 1750 out of 4993, last 50 images took 889.794934 seconds\n",
            "Processing image 1800 out of 4993, last 50 images took 888.635215 seconds\n",
            "Processing image 1850 out of 4993, last 50 images took 885.645678 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform retrieval"
      ],
      "metadata": {
        "id": "XebG4HwqC0mI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From models/research/delf/delf/python/delg\n",
        "!export PYTHONPATH=$PYTHONPATH:/content/drive/MyDrive/5_NCKH/models/research/delf && \\\n",
        "python3 perform_retrieval.py \\\n",
        "  --dataset_file_path ./../training/delg/data/gnd_roxford5k.mat \\\n",
        "  --query_features_dir ./../training/delg/data/oxford5k_features/query \\\n",
        "  --index_features_dir ./../training/delg/data/oxford5k_features/index \\\n",
        "  --output_dir ./../training/delg/results/oxford5k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_0oA9DWCrrE",
        "outputId": "6ba409c6-ab69-484f-dbe4-328401fbcd74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-19 02:38:01.439673: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-19 02:38:01.462433: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-19 02:38:01.469308: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-19 02:38:02.723910: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Parsing dataset...\n",
            "done! Found 70 queries and 4993 index images\n",
            "Starting to collect global descriptors for 70 images...\n",
            "Reading global descriptors for image 50 out of 70, last 50 images took 11.760937 seconds\n",
            "Starting to collect global descriptors for 4993 images...\n",
            "Reading global descriptors for image 50 out of 4993, last 50 images took 16.352439 seconds\n",
            "Reading global descriptors for image 100 out of 4993, last 50 images took 10.923632 seconds\n",
            "Reading global descriptors for image 150 out of 4993, last 50 images took 11.026603 seconds\n",
            "Reading global descriptors for image 200 out of 4993, last 50 images took 11.264635 seconds\n",
            "Reading global descriptors for image 250 out of 4993, last 50 images took 12.217009 seconds\n",
            "Reading global descriptors for image 300 out of 4993, last 50 images took 11.099138 seconds\n",
            "Reading global descriptors for image 350 out of 4993, last 50 images took 11.830917 seconds\n",
            "Reading global descriptors for image 400 out of 4993, last 50 images took 11.453368 seconds\n",
            "Reading global descriptors for image 450 out of 4993, last 50 images took 11.582372 seconds\n",
            "Reading global descriptors for image 500 out of 4993, last 50 images took 11.385583 seconds\n",
            "Reading global descriptors for image 550 out of 4993, last 50 images took 11.244663 seconds\n",
            "Reading global descriptors for image 600 out of 4993, last 50 images took 12.197477 seconds\n",
            "Reading global descriptors for image 650 out of 4993, last 50 images took 10.676263 seconds\n",
            "Reading global descriptors for image 700 out of 4993, last 50 images took 10.915416 seconds\n",
            "Reading global descriptors for image 750 out of 4993, last 50 images took 11.490497 seconds\n",
            "Reading global descriptors for image 800 out of 4993, last 50 images took 11.490678 seconds\n",
            "Reading global descriptors for image 850 out of 4993, last 50 images took 11.792207 seconds\n",
            "Reading global descriptors for image 900 out of 4993, last 50 images took 13.275292 seconds\n",
            "Reading global descriptors for image 950 out of 4993, last 50 images took 11.555997 seconds\n",
            "Reading global descriptors for image 1000 out of 4993, last 50 images took 10.733535 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/delg/perform_retrieval.py\", line 224, in <module>\n",
            "    app.run(main)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/delg/perform_retrieval.py\", line 128, in main\n",
            "    index_global_features = _ReadDelgGlobalDescriptors(FLAGS.index_features_dir,\n",
            "  File \"/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/delg/perform_retrieval.py\", line 105, in _ReadDelgGlobalDescriptors\n",
            "    global_descriptors.append(datum_io.ReadFromFile(descriptor_fullpath))\n",
            "  File \"/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/datum_io.py\", line 183, in ReadFromFile\n",
            "    return ParseFromString(f.read())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\", line 116, in read\n",
            "    self._preread_check()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\", line 77, in _preread_check\n",
            "    self._read_buf = _pywrap_file_io.BufferedInputStream(\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: ./../training/delg/data/oxford5k_features/index/magdalen_000317.delg_global; No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "A_n_F-88Gcq_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset GLDv2"
      ],
      "metadata": {
        "id": "icc2UJ5AGi_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "id": "cUmwhRQjHgGq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4b58d983-aade-4756-c6e5-e89e10174744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/training'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/training\")"
      ],
      "metadata": {
        "id": "6HckSlwpHh_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash download_dataset.sh 10 2 1 #500 100 20"
      ],
      "metadata": {
        "id": "NKQ1NCaWGeyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the Data for Training"
      ],
      "metadata": {
        "id": "STasEckuHVwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 build_image_dataset.py \\\n",
        "  --train_csv_path=gldv2_dataset/train/train.csv \\\n",
        "  --train_clean_csv_path=gldv2_dataset/train/train_clean.csv \\\n",
        "  --train_directory=gldv2_dataset/train/*/*/*/ \\\n",
        "  --output_directory=gldv2_dataset/tfrecord/ \\\n",
        "  --num_shards=128 \\\n",
        "  --generate_train_validation_splits \\\n",
        "  --validation_split_size=0.2"
      ],
      "metadata": {
        "id": "AciNbPqOHVKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f27ad8e-eac6-491d-d2dc-0a4e4fdbb9fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-19 13:59:45.208699: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-19 13:59:45.243384: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-19 13:59:45.253642: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-19 13:59:45.279399: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-19 13:59:47.033114: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loading CSV BEFORE\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/training/build_image_dataset.py\", line 497, in <module>\n",
            "    app.run(main)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/training/build_image_dataset.py\", line 486, in main\n",
            "    _build_train_tfrecord_dataset(FLAGS.train_csv_path,\n",
            "  File \"/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/training/build_image_dataset.py\", line 445, in _build_train_tfrecord_dataset\n",
            "    relabeling_rules) = _get_clean_train_image_files_and_labels(clean_csv_path,\n",
            "  File \"/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/training/build_image_dataset.py\", line 149, in _get_clean_train_image_files_and_labels\n",
            "    csv_data = StringIO(file_content)\n",
            "TypeError: initial_value must be str or None, not bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 build_image_dataset.py \\\n",
        "  --test_csv_path=gldv2_dataset/train/test.csv \\\n",
        "  --test_directory=gldv2_dataset/test/*/*/*/ \\\n",
        "  --output_directory=gldv2_dataset/tfrecord/ \\\n",
        "  --num_shards=128 \\\n",
        "  --generate_train_validation_splits \\\n",
        "  --validation_split_size=0.2"
      ],
      "metadata": {
        "id": "m8X7WZKEIvr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the Training"
      ],
      "metadata": {
        "id": "52Smv0isJTiM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download ImageNet checkpoint"
      ],
      "metadata": {
        "id": "M67UPVuCJWu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -Os http://storage.googleapis.com/delf/resnet50_imagenet_weights.tar.gz\n",
        "!tar -xzvf resnet50_imagenet_weights.tar.gz"
      ],
      "metadata": {
        "id": "NUqEKfkZJUwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with Local and Global Features"
      ],
      "metadata": {
        "id": "NFV9p8JJJoKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py \\\n",
        "  --train_file_pattern=gldv2_dataset/tfrecord/train* \\\n",
        "  --validation_file_pattern=gldv2_dataset/tfrecord/validation* \\\n",
        "  --imagenet_checkpoint=resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "  --dataset_version=gld_v2_clean \\\n",
        "  --logdir=gldv2_training/ \\\n",
        "  --delg_global_features"
      ],
      "metadata": {
        "id": "1xz47C7IJnt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Guidelines\n",
        "In order to improve the convergence of the training, the following hyperparameter values have been tested and validated on the following infrastructures, the remaining train.py flags keeping their default values:\n",
        "\n",
        "8 Tesla P100 GPUs: --batch_size=256, --initial_lr=0.01\n",
        "\n",
        "4 Tesla P100 GPUs: --batch_size=128, --initial_lr=0.005"
      ],
      "metadata": {
        "id": "6jK630IOJ2tJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Push github"
      ],
      "metadata": {
        "id": "bMB_p15BplqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "YZgZZYHZou7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "w5LpP-Xgpr-l",
        "outputId": "743eb686-f397-460c-9d04-869fbd965ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/MyDrive/5_NCKH/models/research/delf\")"
      ],
      "metadata": {
        "id": "1CX6kdiWpt-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j6txCpSpoaH",
        "outputId": "9d026f99-9b90-499a-ff7f-edde658f9d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/drive/MyDrive/5_NCKH/models/research/delf/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch"
      ],
      "metadata": {
        "id": "A7jSY5tMqHJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05963823-b8d4-475f-dc28-432207765af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* \u001b[32mmain\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZofHYwqDZk4b",
        "outputId": "38fb52f2-9dcd-461e-fef4-8efb30d4632a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31m.gitignore\u001b[m\n",
            "\t\u001b[31mDETECTION.md\u001b[m\n",
            "\t\u001b[31mEXTRACTION_MATCHING.md\u001b[m\n",
            "\t\u001b[31mINSTALL_INSTRUCTIONS.md\u001b[m\n",
            "\t\u001b[31mbuild/\u001b[m\n",
            "\t\u001b[31mdelf.egg-info/\u001b[m\n",
            "\t\u001b[31mdelf/\u001b[m\n",
            "\t\u001b[31msetup.py\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile .gitignore\n",
        "# .git\n",
        "# delf/python/delg/training/delg/data/\n",
        "# delf/python/delg/parameters/\n",
        "# delf/python/training/gldv2_dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTnG4ELhZxHv",
        "outputId": "7ded6115-772a-4fff-cd6a-586ec22cafe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting .gitignore\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat .gitignore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSPhQ7ITqz8O",
        "outputId": "8eac533a-6024-4ff2-b6cd-b15e9adaf624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".git\n",
            "delf/python/delg/training/delg/data/\n",
            "delf/python/delg/parameters/\n",
            "delf/python/training/gldv2_dataset/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xyu3Ms0Qgog2",
        "outputId": "96e7cf98-9317-4672-e552-a0e3a29112fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31m.gitignore\u001b[m\n",
            "\t\u001b[31mDETECTION.md\u001b[m\n",
            "\t\u001b[31mEXTRACTION_MATCHING.md\u001b[m\n",
            "\t\u001b[31mINSTALL_INSTRUCTIONS.md\u001b[m\n",
            "\t\u001b[31mbuild/\u001b[m\n",
            "\t\u001b[31mdelf.egg-info/\u001b[m\n",
            "\t\u001b[31mdelf/\u001b[m\n",
            "\t\u001b[31msetup.py\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add README.md"
      ],
      "metadata": {
        "id": "TEuFlm5ad2FI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"phucknguyen123456789@gmail.com\"\n",
        "!git config --global user.name \"toilaphucnguyen\""
      ],
      "metadata": {
        "id": "bqBSDIBdg8f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git config --global --unset user.email\n",
        "# !git config --global --unset user.name"
      ],
      "metadata": {
        "id": "3RgLGOUVkZGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"first commit\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZK9HOLhd58x",
        "outputId": "8302bb38-083c-42d5-e978-5a4f1c33197d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31m.gitignore\u001b[m\n",
            "\t\u001b[31mDETECTION.md\u001b[m\n",
            "\t\u001b[31mEXTRACTION_MATCHING.md\u001b[m\n",
            "\t\u001b[31mINSTALL_INSTRUCTIONS.md\u001b[m\n",
            "\t\u001b[31mbuild/\u001b[m\n",
            "\t\u001b[31mdelf.egg-info/\u001b[m\n",
            "\t\u001b[31mdelf/\u001b[m\n",
            "\t\u001b[31msetup.py\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote add origin https://nguyenvanhoangphuc:3qUmBkpc8xepmE8vZ8+dJGbXhKhwNyjWraAqUzzEOnU@git@github.com:nguyenvanhoangphuc/DELF.git"
      ],
      "metadata": {
        "id": "R4aGQ_4-qFf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-lm-ZdqeqsYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !git remote remove origin"
      ],
      "metadata": {
        "id": "brY2n9fvrS-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op3cB-M7h3tq",
        "outputId": "e7fd0deb-c0b7-4f29-a5af-7065073d6f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "origin\thttps://nguyenvanhoangphuc:3qUmBkpc8xepmE8vZ8+dJGbXhKhwNyjWraAqUzzEOnU@github.com/nguyenvanhoangphuc/DELF.git (fetch)\n",
            "origin\thttps://nguyenvanhoangphuc:3qUmBkpc8xepmE8vZ8+dJGbXhKhwNyjWraAqUzzEOnU@github.com/nguyenvanhoangphuc/DELF.git (push)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push -u origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjbdfAquhi68",
        "outputId": "f523be1b-0e5a-427f-c853-1b817ef193e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Support for password authentication was removed on August 13, 2021.\n",
            "remote: Please see https://docs.github.com/get-started/getting-started-with-git/about-remote-repositories#cloning-with-https-urls for information on currently recommended modes of authentication.\n",
            "fatal: Authentication failed for 'https://github.com/nguyenvanhoangphuc/reponame.git/'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nháp"
      ],
      "metadata": {
        "id": "rxBoZ918pgtE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Init"
      ],
      "metadata": {
        "id": "5J0-KQAJaONY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/5_NCKH/Phuc/models/research/delf/delf/python/training')"
      ],
      "metadata": {
        "id": "Vo8g0HkVMSS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5FUgeDcMq7G",
        "outputId": "14d9b018-09ca-4f4a-940b-bc38b76c16db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build_image_dataset.py\t  matched_images_demo.png\n",
            "download_dataset.sh\t  model\n",
            "gldv2_dataset\t\t  README.md\n",
            "global_features\t\t  resnet50_imagenet_weights.tar.gz\n",
            "global_features_utils.py  resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "__init__.py\t\t  tensorboard_utils.py\n",
            "install_delf.sh\t\t  train.py\n",
            "losses\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf gldv2_dataset/"
      ],
      "metadata": {
        "id": "OIPCviK8iayd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !bash download_dataset.sh 5 1 1 # 500 100 20"
      ],
      "metadata": {
        "id": "LbersWmeMZTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "có thể remove các file .tar sau khi đã download xong"
      ],
      "metadata": {
        "id": "ILmoamspNZtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "0yyVzbD5TPzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Image Dataset"
      ],
      "metadata": {
        "id": "lADTsO3bz3xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 build_image_dataset.py \\\n",
        "#   --train_csv_path=gldv2_dataset/train/train.csv \\\n",
        "#   --train_clean_csv_path=gldv2_dataset/train/train_clean.csv \\\n",
        "#   --train_directory=gldv2_dataset/train/*/*/*/ \\\n",
        "#   --output_directory=gldv2_dataset/tfrecord/ \\\n",
        "#   --num_shards=128 \\\n",
        "#   --generate_train_validation_splits \\\n",
        "#   --validation_split_size=0.2"
      ],
      "metadata": {
        "id": "cUlQQEL_Nd7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv_path=\"gldv2_dataset/train/train.csv\"\n",
        "train_clean_csv_path=\"gldv2_dataset/train/train_clean.csv\"\n",
        "train_directory=\"gldv2_dataset/train/*/*/*/\"\n",
        "output_directory=\"gldv2_dataset/tfrecord/\"\n",
        "num_shards=12\n",
        "generate_train_validation_splits = True\n",
        "validation_split_size=0.2"
      ],
      "metadata": {
        "id": "1s1-kM3wFsJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import csv, os\n",
        "from absl import app, flags\n",
        "import numpy as np, pandas as pd, tensorflow as tf\n",
        "\n",
        "def _get_all_image_files_and_labels(name, csv_path, image_dir):\n",
        "    image_paths = tf.io.gfile.glob(os.path.join(image_dir, '*.jpg'))\n",
        "    file_ids = [os.path.basename(f)[:-4] for f in image_paths]\n",
        "    if name == 'train':\n",
        "        df = pd.read_csv(tf.io.gfile.GFile(csv_path, 'rb')).set_index('id')\n",
        "        labels = [int(df.loc[fid]['landmark_id']) for fid in file_ids]\n",
        "    elif name == 'test':\n",
        "        labels = []\n",
        "    else:\n",
        "        raise ValueError('Unsupported dataset split name: %s' % name)\n",
        "    return image_paths, file_ids, labels\n",
        "\n",
        "# def _get_clean_train_image_files_and_labels(csv_path, image_dir):\n",
        "#     print(\"_get_clean_train_image_files_and_labels====\"*20)\n",
        "#     print(1)\n",
        "#     # df = pd.read_csv(tf.io.gfile.GFile(csv_path, 'rb'))\n",
        "#     # Open the file with TensorFlow's GFile\n",
        "#     with tf.io.gfile.GFile(csv_path, 'r') as f:\n",
        "#         # Read the file content\n",
        "#         csv_content = f.read()\n",
        "#         # Convert the content to a StringIO buffer\n",
        "#         csv_buffer = io.StringIO(csv_content)\n",
        "#         # Read the CSV using Pandas\n",
        "#         df = pd.read_csv(csv_buffer)\n",
        "#     print(\"_get_clean_train_image_files_and_labels====\"*20)\n",
        "#     print(2)\n",
        "#     images = {file_id: {'label': row['landmark_id'], 'file_id': file_id} for _, row in df.iterrows() for file_id in row['images'].split(' ')}\n",
        "#     print(\"_get_clean_train_image_files_and_labels====\"*20)\n",
        "#     print(3)\n",
        "#     for image_path in tf.io.gfile.glob(os.path.join(image_dir, '*.jpg')):\n",
        "#         file_id = os.path.basename(image_path)[:-4]\n",
        "#         if file_id in images:\n",
        "#             images[file_id]['image_path'] = image_path\n",
        "#     print(\"_get_clean_train_image_files_and_labels====\"*20)\n",
        "#     print(4)\n",
        "#     image_paths, file_ids, labels = zip(*[(v['image_path'], v['file_id'], v['label']) for v in images.values()])\n",
        "#     print(\"_get_clean_train_image_files_and_labels====\"*20)\n",
        "#     print(5)\n",
        "#     unique_labels = sorted(set(labels))\n",
        "#     relabeling = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "#     return list(image_paths), list(file_ids), [relabeling[label] for label in labels], relabeling\n",
        "\n",
        "import logging\n",
        "import io\n",
        "\n",
        "def _get_clean_train_image_files_and_labels(csv_path, image_dir):\n",
        "    \"\"\"Get image file paths, image ids, and labels for the clean training split.\"\"\"\n",
        "\n",
        "    logging.info('Loading CSV file: %s', csv_path)\n",
        "    # Open the file with TensorFlow's GFile\n",
        "    with tf.io.gfile.GFile(csv_path, 'r') as f:\n",
        "        # Read the file content\n",
        "        csv_content = f.read()\n",
        "        # Convert the content to a StringIO buffer\n",
        "        csv_buffer = io.StringIO(csv_content)\n",
        "        # Read the CSV using Pandas\n",
        "        df = pd.read_csv(csv_buffer)\n",
        "    # df = pd.read_csv(tf.io.gfile.GFile(csv_path, 'rb'))\n",
        "\n",
        "    images = {file_id: {'label': row['landmark_id'], 'file_id': file_id}\n",
        "              for _, row in df.iterrows()\n",
        "              for file_id in row['images'].split(' ')}\n",
        "\n",
        "    logging.info('Processing image directory: %s', image_dir)\n",
        "    image_paths = tf.io.gfile.glob(os.path.join(image_dir, '*.jpg'))\n",
        "    for image_path in image_paths:\n",
        "        file_id = os.path.basename(image_path)[:-4]\n",
        "        if file_id in images:\n",
        "            images[file_id]['image_path'] = image_path\n",
        "\n",
        "    image_paths, file_ids, labels = zip(*[(v['image_path'], v['file_id'], v['label'])\n",
        "                                           for v in images.values() if 'image_path' in v])\n",
        "    print(\"_get_clean_train_image_files_and_labels====\"*20)\n",
        "    print(5)\n",
        "    unique_labels = sorted(set(labels))\n",
        "    relabeling = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "    new_labels = [relabeling[label] for label in labels]\n",
        "\n",
        "    logging.info('Finished processing %d images', len(image_paths))\n",
        "    return list(image_paths), list(file_ids), new_labels, relabeling\n",
        "\n",
        "\n",
        "\n",
        "def _process_image(filename):\n",
        "    image_data = tf.io.gfile.GFile(filename, 'rb').read()\n",
        "    image = tf.io.decode_jpeg(image_data, channels=3)\n",
        "    if len(image.shape) != 3 or image.shape[2] != 3:\n",
        "        raise ValueError('Invalid image dimensions/channels')\n",
        "    return image_data, image.shape[0], image.shape[1]\n",
        "\n",
        "def _int64_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _convert_to_example(file_id, image_buffer, height, width, label=None):\n",
        "    features = {\n",
        "        'image/height': _int64_feature(height),\n",
        "        'image/width': _int64_feature(width),\n",
        "        'image/colorspace': _bytes_feature(b'RGB'),\n",
        "        'image/channels': _int64_feature(3),\n",
        "        'image/format': _bytes_feature(b'JPEG'),\n",
        "        'image/id': _bytes_feature(file_id.encode('utf-8')),\n",
        "        'image/encoded': _bytes_feature(image_buffer)\n",
        "    }\n",
        "    if label is not None:\n",
        "        features['image/class/label'] = _int64_feature(label)\n",
        "    return tf.train.Example(features=tf.train.Features(feature=features))\n",
        "\n",
        "def _write_tfrecord(output_prefix, image_paths, file_ids, labels):\n",
        "    if output_prefix == 'test':\n",
        "        labels = [None] * len(image_paths)\n",
        "    if len(image_paths) != len(file_ids) != len(labels):\n",
        "        raise ValueError('Mismatched image_paths, file_ids, labels lengths.')\n",
        "    spacing = np.linspace(0, len(image_paths), num_shards + 1, dtype=int)\n",
        "    for shard in range(num_shards):\n",
        "        output_file = os.path.join(output_directory, f'{output_prefix}-{shard:05d}-of-{num_shards:05d}')\n",
        "        writer = tf.io.TFRecordWriter(output_file)\n",
        "        print('Processing shard', shard, 'writing to', output_file)\n",
        "        for i in range(spacing[shard], spacing[shard + 1]):\n",
        "            image_buffer, height, width = _process_image(image_paths[i])\n",
        "            example = _convert_to_example(file_ids[i], image_buffer, height, width, labels[i])\n",
        "            writer.write(example.SerializeToString())\n",
        "        writer.close()\n",
        "\n",
        "def _write_relabeling_rules(relabeling_rules):\n",
        "    with tf.io.gfile.GFile(os.path.join(output_directory, 'relabeling.csv'), 'w') as relabeling_file:\n",
        "        csv_writer = csv.writer(relabeling_file)\n",
        "        csv_writer.writerow(['new_label', 'old_label'])\n",
        "        for old_label, new_label in relabeling_rules.items():\n",
        "            csv_writer.writerow([new_label, old_label])\n",
        "\n",
        "# def _build_train_and_validation_splits(image_paths, file_ids, labels, validation_split_size, seed):\n",
        "#     total_images = len(file_ids)\n",
        "#     if len(image_paths) != total_images or len(labels) != total_images:\n",
        "#         raise ValueError('Mismatched array lengths for shuffling.')\n",
        "#     labels_str = [str(label) for label in labels]\n",
        "#     image_attrs = np.stack((image_paths, file_ids, labels_str))\n",
        "#     image_attrs_idx_by_label = {label: [idx for idx, _ in enumerate(labels) if labels[idx] == label] for label in set(labels)}\n",
        "#     rs = np.random.RandomState(np.random.SeedSequence(seed))\n",
        "#     splits = {_VALIDATION_SPLIT: [], _TRAIN_SPLIT: []}\n",
        "#     for label, indexes in image_attrs_idx_by_label.items():\n",
        "#         image_attrs_label = image_attrs[:, indexes]\n",
        "#         rs.shuffle(image_attrs_label.T)\n",
        "#         cutoff_idx = max(1, int(validation_split_size * image_attrs_label.shape[1]))\n",
        "#         splits[_VALIDATION_SPLIT].append(image_attrs_label[:, :cutoff_idx])\n",
        "#         splits[_TRAIN_SPLIT].append(image_attrs_label[:, cutoff_idx:])\n",
        "#     validation_split = np.hstack(splits[_VALIDATION_SPLIT]).T\n",
        "#     train_split = np.hstack(splits[_TRAIN_SPLIT]).T\n",
        "#     return {_IMAGE_PATHS_KEY: validation_split[:, 0], _FILE_IDS_KEY: validation_split[:, 1], _LABELS_KEY: list(map(int, validation_split[:, 2]))}, \\\n",
        "#            {_IMAGE_PATHS_KEY: train_split[:, 0], _FILE_IDS_KEY: train_split[:, 1], _LABELS_KEY: list(map(int, train_split[:, 2]))}\n",
        "def _build_train_tfrecord_dataset(csv_path, clean_csv_path, image_dir,\n",
        "                                  generate_train_validation_splits,\n",
        "                                  validation_split_size, seed):\n",
        "  if clean_csv_path:\n",
        "    image_paths, file_ids, labels, relabeling_rules = _get_clean_train_image_files_and_labels(clean_csv_path, image_dir)\n",
        "    _write_relabeling_rules(relabeling_rules)\n",
        "  else:\n",
        "    image_paths, file_ids, labels = _get_all_image_files_and_labels(_TRAIN_SPLIT, csv_path, image_dir)\n",
        "\n",
        "  if generate_train_validation_splits:\n",
        "    validation_split, train_split = _build_train_and_validation_splits(image_paths, file_ids, labels, validation_split_size, seed)\n",
        "    _write_tfrecord(_VALIDATION_SPLIT, validation_split[_IMAGE_PATHS_KEY], validation_split[_FILE_IDS_KEY], validation_split[_LABELS_KEY])\n",
        "    _write_tfrecord(_TRAIN_SPLIT, train_split[_IMAGE_PATHS_KEY], train_split[_FILE_IDS_KEY], train_split[_LABELS_KEY])\n",
        "  else:\n",
        "    _write_tfrecord(_TRAIN_SPLIT, image_paths, file_ids, labels)\n",
        "\n",
        "def _build_train_tfrecord_dataset(csv_path, clean_csv_path, image_dir, generate_train_validation_splits, validation_split_size, seed):\n",
        "    print(\"_build_train_tfrecord_dataset====\"*20)\n",
        "    print(1)\n",
        "    if generate_train_validation_splits and not 0 < validation_split_size < 1:\n",
        "        raise ValueError('Invalid validation split size.')\n",
        "    print(\"_build_train_tfrecord_dataset====\"*20)\n",
        "    print(2)\n",
        "    if clean_csv_path:\n",
        "        image_paths, file_ids, labels, relabeling_rules = _get_clean_train_image_files_and_labels(clean_csv_path, image_dir)\n",
        "        _write_relabeling_rules(relabeling_rules)\n",
        "    else:\n",
        "        image_paths, file_ids, labels = _get_all_image_files_and_labels(_TRAIN_SPLIT, csv_path, image_dir)\n",
        "    print(\"_build_train_tfrecord_dataset====\"*20)\n",
        "    print(3)\n",
        "    if generate_train_validation_splits:\n",
        "        validation_split, train_split = _build_train_and_validation_splits(image_paths, file_ids, labels, validation_split_size, seed)\n",
        "        _write_tfrecord(_VALIDATION_SPLIT, validation_split[_IMAGE_PATHS_KEY], validation_split[_FILE_IDS_KEY], validation_split[_LABELS_KEY])\n",
        "        _write_tfrecord(_TRAIN_SPLIT, train_split[_IMAGE_PATHS_KEY], train_split[_FILE_IDS_KEY], train_split[_LABELS_KEY])\n",
        "    else:\n",
        "        _write_tfrecord(_TRAIN_SPLIT, image_paths, file_ids, labels)\n",
        "\n",
        "def _build_test_tfrecord_dataset(csv_path, image_dir):\n",
        "    image_paths, file_ids, labels = _get_all_image_files_and_labels(_TEST_SPLIT, csv_path, image_dir)\n",
        "    _write_tfrecord(_TEST_SPLIT, image_paths, file_ids, labels)"
      ],
      "metadata": {
        "id": "xzTaLC1dz5sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_build_train_tfrecord_dataset(train_csv_path, train_clean_csv_path, train_directory,\n",
        "                                  generate_train_validation_splits, validation_split_size, seed)\n",
        "if test_csv_path:\n",
        "    _build_test_tfrecord_dataset(test_csv_path, test_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "0u3lwGO4gniv",
        "outputId": "7941e268-5f48-47b9-d77a-85fe8485bc30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====\n",
            "1\n",
            "_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====_build_train_tfrecord_dataset====\n",
            "2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-bbc07ed4ba76>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m _build_train_tfrecord_dataset(train_csv_path, train_clean_csv_path, train_directory,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                   generate_train_validation_splits, validation_split_size, seed)\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtest_csv_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0m_build_test_tfrecord_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_csv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-46c9b1fdeff4>\u001b[0m in \u001b[0;36m_build_train_tfrecord_dataset\u001b[0;34m(csv_path, clean_csv_path, image_dir, generate_train_validation_splits, validation_split_size, seed)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclean_csv_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelabeling_rules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_clean_train_image_files_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_csv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0m_write_relabeling_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelabeling_rules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-46c9b1fdeff4>\u001b[0m in \u001b[0;36m_get_clean_train_image_files_and_labels\u001b[0;34m(csv_path, image_dir)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Processing image directory: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mfile_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mget_matching_files_v2\u001b[0;34m(pattern)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# Convert the filenames to string from bytes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         for matching_filename in _pywrap_file_io.GetMatchingFiles(\n\u001b[0m\u001b[1;32m    442\u001b[0m             compat.as_bytes(pattern))\n\u001b[1;32m    443\u001b[0m     ]\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Test Dataset"
      ],
      "metadata": {
        "id": "oGiik8Eav10I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --test_csv_path=gldv2_dataset/train/test.csv \\\n",
        "# --test_directory=gldv2_dataset/test/*/*/*/ \\"
      ],
      "metadata": {
        "id": "SMj_Vu9Xv8yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_csv_path = \"gldv2_dataset/train/test.csv\"\n",
        "test_directory = \"gldv2_dataset/test/*/*/*/\""
      ],
      "metadata": {
        "id": "Kp3HetcEwE1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if test_csv_path:\n",
        "    _build_test_tfrecord_dataset(test_csv_path, test_directory)"
      ],
      "metadata": {
        "id": "gKmu6El2v_6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running the Training"
      ],
      "metadata": {
        "id": "234s_EG0A3nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !curl -Os http://storage.googleapis.com/delf/resnet50_imagenet_weights.tar.gz\n",
        "# !tar -xzvf resnet50_imagenet_weights.tar.gz"
      ],
      "metadata": {
        "id": "Zy0F9mofA3JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with Local Features"
      ],
      "metadata": {
        "id": "rFdUauVRBMFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/training\")"
      ],
      "metadata": {
        "id": "UY9zpJVmZoHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash install_delf.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqWEet2SZjRW",
        "outputId": "22b177b9-10ff-4720-ec4d-cb03fbd6f036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing TensorFlow\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (69.5.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.1)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n",
            "Installing TensorFlow 2.16 for GPU\n",
            "Installing TF-Slim from source: \n",
            "Cloning into 'tf-slim'...\n",
            "remote: Enumerating objects: 834, done.\u001b[K\n",
            "remote: Counting objects: 100% (207/207), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 834 (delta 138), reused 178 (delta 129), pack-reused 627 (from 1)\u001b[K\n",
            "Receiving objects: 100% (834/834), 799.35 KiB | 5.16 MiB/s, done.\n",
            "Resolving deltas: 100% (578/578), done.\n",
            "Note: switching to 'a143c8241b12e00a441678f9d527c6a488166863'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "Processing /content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/training/tf-slim\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf_slim==1.1.0) (1.4.0)\n",
            "Building wheels for collected packages: tf_slim\n",
            "  Building wheel for tf_slim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tf_slim: filename=tf_slim-1.1.0-py3-none-any.whl size=355173 sha256=865a95b7eae93506ed7f428a9c22078ffb59a0cdc97aef0766cd52a8e3b5c665\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/85/6f/140c4c2aa75dfc237f79b7fd889687b5230a255603ef8798bb\n",
            "Successfully built tf_slim\n",
            "Installing collected packages: tf_slim\n",
            "  Attempting uninstall: tf_slim\n",
            "    Found existing installation: tf_slim 1.1.0\n",
            "    Uninstalling tf_slim-1.1.0:\n",
            "      Successfully uninstalled tf_slim-1.1.0\n",
            "Successfully installed tf_slim-1.1.0\n",
            "Downloading Protobuf compiler from https://github.com/google/protobuf/releases/download/v3.3.0/protoc-3.3.0-linux-x86_64.zip\n",
            "Archive:  protoc-3.3.0-linux-x86_64.zip\n",
            "   creating: protoc/include/\n",
            "   creating: protoc/include/google/\n",
            "   creating: protoc/include/google/protobuf/\n",
            "  inflating: protoc/include/google/protobuf/any.proto  \n",
            "  inflating: protoc/include/google/protobuf/api.proto  \n",
            "   creating: protoc/include/google/protobuf/compiler/\n",
            "  inflating: protoc/include/google/protobuf/compiler/plugin.proto  \n",
            "  inflating: protoc/include/google/protobuf/descriptor.proto  \n",
            "  inflating: protoc/include/google/protobuf/duration.proto  \n",
            "  inflating: protoc/include/google/protobuf/empty.proto  \n",
            "  inflating: protoc/include/google/protobuf/field_mask.proto  \n",
            "  inflating: protoc/include/google/protobuf/source_context.proto  \n",
            "  inflating: protoc/include/google/protobuf/struct.proto  \n",
            "  inflating: protoc/include/google/protobuf/timestamp.proto  \n",
            "  inflating: protoc/include/google/protobuf/type.proto  \n",
            "  inflating: protoc/include/google/protobuf/wrappers.proto  \n",
            "   creating: protoc/bin/\n",
            "  inflating: protoc/bin/protoc       \n",
            "  inflating: protoc/readme.txt       \n",
            "Compiling DELF Protobufs\n",
            "Cleaning up Protobuf compiler download\n",
            "Installing matplotlib, numpy, scikit-image, scipy and python3-tk\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.23.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.3)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.8.30)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-tk is already the newest version (3.10.8-1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Installing object detection\n",
            "\u001b[31mERROR: Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0mUnable to install the object_detection package. Exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/5_NCKH/Phuc/models/research/delf/delf/python/training"
      ],
      "metadata": {
        "id": "1cpxBF1fpVL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce1e84e-248c-49f2-e3d9-a4027d86f10f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import delf\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZunWd7ckSBXq",
        "outputId": "9ebedc15-2f28-4d0f-e138-0933b5f7b61b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "ModuleNotFoundError: No module named 'delf'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "current_path = '/content/drive/MyDrive/5_NCKH/models/research/delf'\n",
        "sys.path.append(current_path)\n",
        "\n",
        "# Bây giờ import delf\n",
        "from delf.python.datasets.google_landmarks_dataset import googlelandmarks as gld"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ghV8GyQ0VC-p",
        "outputId": "57885a29-356e-4b36-c597-5ea31af9eddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'delf.python'; 'delf' is not a package",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-1a35564f1231>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Bây giờ import delf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdelf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoogle_landmarks_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgooglelandmarks\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgld\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'delf.python'; 'delf' is not a package",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py \\\n",
        "  --train_file_pattern=gldv2_dataset/tfrecord/train* \\\n",
        "  --validation_file_pattern=gldv2_dataset/tfrecord/validation* \\\n",
        "  --imagenet_checkpoint=resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "  --dataset_version=gld_v2_clean \\\n",
        "  --logdir=gldv2_training/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dIhanCbBMkg",
        "outputId": "021ad833-b87d-409f-b2c3-4b64d2c71544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-21 11:26:27.392205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-21 11:26:27.414159: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-21 11:26:27.420864: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-21 11:26:27.437541: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-09-21 11:26:28.891611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/5_NCKH/models/research/delf/delf/python/training/train.py\", line 36, in <module>\n",
            "    from delf.python.datasets.google_landmarks_dataset import googlelandmarks as gld\n",
            "ModuleNotFoundError: No module named 'delf'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with Local and Global Features"
      ],
      "metadata": {
        "id": "gUbKEECIBXZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py \\\n",
        "  --train_file_pattern=gldv2_dataset/tfrecord/train* \\\n",
        "  --validation_file_pattern=gldv2_dataset/tfrecord/validation* \\\n",
        "  --imagenet_checkpoint=resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "  --dataset_version=gld_v2_clean \\\n",
        "  --logdir=gldv2_training/ \\\n",
        "  --delg_global_features"
      ],
      "metadata": {
        "id": "O9HLhD1wBW0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dOUmOA7VBa-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nháp"
      ],
      "metadata": {
        "id": "sRW8BzB9vW76"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### build image Dataset"
      ],
      "metadata": {
        "id": "NqTPcPv8yWbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _write_relabeling_rules(relabeling_rules):\n",
        "    \"\"\"Write relabeling rules to a CSV file.\"\"\"\n",
        "    with tf.io.gfile.GFile(os.path.join(output_directory, 'relabeling.csv'), 'w') as f:\n",
        "        csv.writer(f).writerows([['new_label', 'old_label']] + [[v, k] for k, v in relabeling_rules.items()])"
      ],
      "metadata": {
        "id": "2Ianme6KZdnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def _bytes_feature(value):\n",
        "#     return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\n",
        "def _bytes_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
      ],
      "metadata": {
        "id": "O7P_XeZOeQQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _process_image(filename):\n",
        "    \"\"\"Process a single image file.\"\"\"\n",
        "    image_data = tf.io.read_file(filename)  # Read the image file\n",
        "    image = tf.io.decode_jpeg(image_data, channels=3)  # Decode the image\n",
        "\n",
        "    # Ensure the image has the correct dimensions and channels\n",
        "    if image.shape[-1] != 3:\n",
        "        raise ValueError(f'Expected 3 channels, but got {image.shape[-1]}')\n",
        "\n",
        "    return image_data, image.shape[0], image.shape[1]"
      ],
      "metadata": {
        "id": "6XVxWnEUdZH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_all_image_files_and_labels(name, csv_path, image_dir):\n",
        "    \"\"\"Get image file paths, ids, and labels from the dataset.\"\"\"\n",
        "    image_paths = tf.io.gfile.glob(os.path.join(image_dir, '*.jpg'))\n",
        "    file_ids = [os.path.basename(f)[:-4] for f in image_paths]\n",
        "\n",
        "    if name == _TRAIN_SPLIT:\n",
        "        df = pd.read_csv(tf.io.gfile.GFile(csv_path, 'rb')).set_index('id')\n",
        "        labels = [int(df.loc[fid]['landmark_id']) for fid in file_ids]\n",
        "    elif name == _TEST_SPLIT:\n",
        "        labels = []\n",
        "    else:\n",
        "        raise ValueError(f'Unsupported dataset split name: {name}')\n",
        "\n",
        "    return image_paths, file_ids, labels"
      ],
      "metadata": {
        "id": "IIiVI_kHZyDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _convert_to_example(file_id, image_buffer, height, width, label=None):\n",
        "    \"\"\"Build an Example proto for the given inputs.\"\"\"\n",
        "    features = {\n",
        "        'image/height': _int64_feature(height),\n",
        "        'image/width': _int64_feature(width),\n",
        "        'image/id': _bytes_feature(file_id.encode('utf-8')),\n",
        "        'image/encoded': _bytes_feature(image_buffer)\n",
        "    }\n",
        "    if label is not None:\n",
        "        features['image/class/label'] = _int64_feature(label)\n",
        "\n",
        "    return tf.train.Example(features=tf.train.Features(feature=features))"
      ],
      "metadata": {
        "id": "sS8lBLXsd-D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import io\n",
        "\n",
        "def _get_clean_train_image_files_and_labels(csv_path, image_dir):\n",
        "    \"\"\"Get image file paths, image ids, and labels for the clean training split.\"\"\"\n",
        "\n",
        "    logging.info('Loading CSV file: %s', csv_path)\n",
        "    # Open the file with TensorFlow's GFile\n",
        "    with tf.io.gfile.GFile(csv_path, 'r') as f:\n",
        "        # Read the file content\n",
        "        csv_content = f.read()\n",
        "        # Convert the content to a StringIO buffer\n",
        "        csv_buffer = io.StringIO(csv_content)\n",
        "        # Read the CSV using Pandas\n",
        "        df = pd.read_csv(csv_buffer)\n",
        "    # df = pd.read_csv(tf.io.gfile.GFile(csv_path, 'rb'))\n",
        "\n",
        "    images = {file_id: {'label': row['landmark_id'], 'file_id': file_id}\n",
        "              for _, row in df.iterrows()\n",
        "              for file_id in row['images'].split(' ')}\n",
        "\n",
        "    logging.info('Processing image directory: %s', image_dir)\n",
        "    image_paths = tf.io.gfile.glob(os.path.join(image_dir, '*.jpg'))\n",
        "    for image_path in image_paths:\n",
        "        file_id = os.path.basename(image_path)[:-4]\n",
        "        if file_id in images:\n",
        "            images[file_id]['image_path'] = image_path\n",
        "\n",
        "    image_paths, file_ids, labels = zip(*[(v['image_path'], v['file_id'], v['label'])\n",
        "                                           for v in images.values() if 'image_path' in v])\n",
        "    print(\"_get_clean_train_image_files_and_labels====\"*20)\n",
        "    print(5)\n",
        "    unique_labels = sorted(set(labels))\n",
        "    relabeling = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "    new_labels = [relabeling[label] for label in labels]\n",
        "\n",
        "    logging.info('Finished processing %d images', len(image_paths))\n",
        "    return list(image_paths), list(file_ids), new_labels, relabeling\n",
        "\n"
      ],
      "metadata": {
        "id": "jev-uEKFYpRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _write_tfrecord(output_prefix, image_paths, file_ids, labels):\n",
        "    \"\"\"Writes image and label data into TFRecord files.\"\"\"\n",
        "    if output_prefix == _TEST_SPLIT:\n",
        "        labels = [None] * len(image_paths)\n",
        "\n",
        "    if len(image_paths) != len(file_ids) or len(image_paths) != len(labels):\n",
        "        raise ValueError(f'Lengths of image_paths ({len(image_paths)}), file_ids ({len(file_ids)}), and labels ({len(labels)}) must match.')\n",
        "\n",
        "    spacing = np.linspace(0, len(image_paths), num_shards + 1, dtype=int)\n",
        "\n",
        "    for shard in range(num_shards):\n",
        "        output_file = os.path.join(output_directory, f'{output_prefix}-{shard:05d}-of-{num_shards:05d}')\n",
        "        with tf.io.TFRecordWriter(output_file) as writer:\n",
        "            print(f'Processing shard {shard} and writing file {output_file}')\n",
        "            for i in range(spacing[shard], spacing[shard + 1]):\n",
        "                image_buffer, height, width = _process_image(image_paths[i])\n",
        "                example = _convert_to_example(file_ids[i], image_buffer, height, width, labels[i])\n",
        "                writer.write(example.SerializeToString())"
      ],
      "metadata": {
        "id": "h7NomKncXSzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _build_train_tfrecord_dataset(csv_path, clean_csv_path, image_dir,\n",
        "                                  generate_train_validation_splits,\n",
        "                                  validation_split_size, seed):\n",
        "  if clean_csv_path:\n",
        "    image_paths, file_ids, labels, relabeling_rules = _get_clean_train_image_files_and_labels(clean_csv_path, image_dir)\n",
        "    _write_relabeling_rules(relabeling_rules)\n",
        "  else:\n",
        "    image_paths, file_ids, labels = _get_all_image_files_and_labels(_TRAIN_SPLIT, csv_path, image_dir)\n",
        "\n",
        "  if generate_train_validation_splits:\n",
        "    validation_split, train_split = _build_train_and_validation_splits(image_paths, file_ids, labels, validation_split_size, seed)\n",
        "    _write_tfrecord(_VALIDATION_SPLIT, validation_split[_IMAGE_PATHS_KEY], validation_split[_FILE_IDS_KEY], validation_split[_LABELS_KEY])\n",
        "    _write_tfrecord(_TRAIN_SPLIT, train_split[_IMAGE_PATHS_KEY], train_split[_FILE_IDS_KEY], train_split[_LABELS_KEY])\n",
        "  else:\n",
        "    _write_tfrecord(_TRAIN_SPLIT, image_paths, file_ids, labels)"
      ],
      "metadata": {
        "id": "LdhI5EgeWJrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _build_test_tfrecord_dataset(csv_path, image_dir):\n",
        "  \"\"\"Build a TFRecord dataset for the 'test' split.\"\"\"\n",
        "  image_paths, file_ids, labels = _get_all_image_files_and_labels(\n",
        "      _TEST_SPLIT, csv_path, image_dir)\n",
        "  _write_tfrecord(_TEST_SPLIT, image_paths, file_ids, labels)"
      ],
      "metadata": {
        "id": "EeM6n1dneHS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_build_train_tfrecord_dataset(train_csv_path,\n",
        "                              train_clean_csv_path,\n",
        "                              train_directory,\n",
        "                              generate_train_validation_splits,\n",
        "                              validation_split_size,\n",
        "                              seed)\n",
        "if test_csv_path is not None:\n",
        "  _build_test_tfrecord_dataset(test_csv_path, test_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "WyH-oByxTwDM",
        "outputId": "f5bb4c03-4e10-480b-d258-43cf0afa154b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====_get_clean_train_image_files_and_labels====\n",
            "5\n",
            "Processing shard 0 and writing file ./gldv2_dataset/tfrecord/train-00000-of-00128\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00 has type tensorflow.python.framework.ops.EagerTensor, but expected one of: bytes",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-750d49f92eb8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m _build_train_tfrecord_dataset(train_csv_path,\n\u001b[0m\u001b[1;32m      2\u001b[0m                               \u001b[0mtrain_clean_csv_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0mtrain_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0mgenerate_train_validation_splits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0mvalidation_split_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-ed0f1b26f3b4>\u001b[0m in \u001b[0;36m_build_train_tfrecord_dataset\u001b[0;34m(csv_path, clean_csv_path, image_dir, generate_train_validation_splits, validation_split_size, seed)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0m_write_tfrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_TRAIN_SPLIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_IMAGE_PATHS_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_FILE_IDS_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_LABELS_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0m_write_tfrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_TRAIN_SPLIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-61a10a77319b>\u001b[0m in \u001b[0;36m_write_tfrecord\u001b[0;34m(output_prefix, image_paths, file_ids, labels)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspacing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshard\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mimage_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_to_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-21020121c6e9>\u001b[0m in \u001b[0;36m_convert_to_example\u001b[0;34m(file_id, image_buffer, height, width, label)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m'image/width'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_int64_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;34m'image/id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_bytes_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;34m'image/encoded'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_bytes_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     }\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-dce7d3b5fb2f>\u001b[0m in \u001b[0;36m_bytes_feature\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#     return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_bytes_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_int64_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: <tf.Tensor: shape=(), dtype=string, numpy=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00 has type tensorflow.python.framework.ops.EagerTensor, but expected one of: bytes"
          ]
        }
      ]
    }
  ]
}